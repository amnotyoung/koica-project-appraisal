"""
KOICA ì‚¬ì—… ì˜ˆë¹„ì¡°ì‚¬ ì‹¬ì‚¬ ì‹œìŠ¤í…œ - ì‹¬ì‚¬ ì—”ì§„
AI ê¸°ë°˜ ì‚¬ì—… ì‹¬ì‚¬ ë¡œì§ êµ¬í˜„
"""

import json
import logging
import traceback
from datetime import datetime
from typing import Dict, Any, Optional, List
import streamlit as st
import PyPDF2
import google.generativeai as genai
from google.generativeai.types import GenerationConfig

from core.models import AuditEvidence
from core.vector_store import SimpleVectorStore
from config import (
    RAGConfig, APIConfig, AuditConfig, UIConfig
)

logger = logging.getLogger(__name__)


class KOICAAuditorStreamlit:
    """KOICA ì‹¬ì‚¬ ì‹œìŠ¤í…œ - RAG v3 (ê°œì„ )

    Retrieval-Augmented Generationì„ í™œìš©í•œ ì‚¬ì—… ì‹¬ì‚¬ ì—”ì§„
    """

    def __init__(self, api_key: Optional[str] = None):
        """ì‹œìŠ¤í…œ ì´ˆê¸°í™”

        Args:
            api_key: Gemini API í‚¤

        Raises:
            ValueError: API í‚¤ê°€ ì—†ëŠ” ê²½ìš°
            Exception: API ì—°ê²° ì‹¤íŒ¨
        """
        if not api_key:
            raise ValueError("Gemini API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤")

        try:
            genai.configure(api_key=api_key)

            # JSON ëª¨ë“œ ì„¤ì •
            self.json_config = GenerationConfig(
                response_mime_type="application/json"
            )

            # Gemini ëª¨ë¸ ì´ˆê¸°í™”
            self.model = genai.GenerativeModel(
                APIConfig.GENERATIVE_MODEL,
                generation_config=self.json_config
            )

            self.api_key = api_key
            logger.info("KOICAAuditorStreamlit ì´ˆê¸°í™” ì™„ë£Œ")

        except Exception as e:
            logger.error(f"Gemini API ì—°ê²° ì‹¤íŒ¨: {e}")
            raise Exception(f"Gemini API ì—°ê²° ì‹¤íŒ¨: {e}")

    def extract_text_from_pdf(self, pdf_file) -> str:
        """PDFì—ì„œ ì „ì²´ í…ìŠ¤íŠ¸ ì¶”ì¶œ

        Args:
            pdf_file: PDF íŒŒì¼ ê°ì²´ (Streamlit UploadedFile)

        Returns:
            ì¶”ì¶œëœ í…ìŠ¤íŠ¸

        Raises:
            Exception: PDF ì²˜ë¦¬ ì‹¤íŒ¨
        """
        try:
            pdf_reader = PyPDF2.PdfReader(pdf_file)
            full_text = ""
            total_pages = len(pdf_reader.pages)

            logger.info(f"PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œì‘ (ì´ {total_pages} í˜ì´ì§€)")
            progress_bar = st.progress(0, text="ğŸ“„ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘...")

            for page_num, page in enumerate(pdf_reader.pages, 1):
                try:
                    full_text += page.extract_text() + "\n"
                    progress = page_num / total_pages
                    progress_bar.progress(
                        progress,
                        text=f"í˜ì´ì§€ ì¶”ì¶œ ì¤‘: {page_num}/{total_pages}"
                    )
                except Exception as e:
                    logger.warning(f"í˜ì´ì§€ {page_num} ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                    st.warning(f"í˜ì´ì§€ {page_num} ì²˜ë¦¬ ì˜¤ë¥˜ (ê±´ë„ˆëœ€)")

            progress_bar.empty()
            logger.info(f"PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ ({len(full_text)} ë¬¸ì)")
            return full_text

        except Exception as e:
            logger.error(f"PDF ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            raise Exception(f"PDF ì²˜ë¦¬ ì˜¤ë¥˜: {e}")

    def create_vector_store(self, full_text: str) -> Optional[SimpleVectorStore]:
        """í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë‚˜ëˆ„ê³  ë²¡í„° ìŠ¤í† ì–´ ìƒì„±

        Args:
            full_text: ì „ì²´ í…ìŠ¤íŠ¸

        Returns:
            ìƒì„±ëœ ë²¡í„° ìŠ¤í† ì–´ ë˜ëŠ” None
        """
        if not full_text:
            logger.error("ì¶”ì¶œëœ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤")
            st.error("ì¶”ì¶œëœ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None

        # í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• 
        chunks = self._split_text(
            full_text,
            chunk_size=RAGConfig.CHUNK_SIZE,
            overlap=RAGConfig.CHUNK_OVERLAP
        )

        if not chunks:
            logger.error("í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë‚˜ëˆŒ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            st.error("í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë‚˜ëˆŒ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None

        st.info(f"ğŸ“¦ ì´ {len(chunks)}ê°œ ì²­í¬ ìƒì„±ë¨")
        logger.info(f"í…ìŠ¤íŠ¸ë¥¼ {len(chunks)}ê°œ ì²­í¬ë¡œ ë¶„í• ")

        try:
            vector_store = SimpleVectorStore(self.api_key)
            vector_store.add_texts(chunks)
            logger.info("ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ")
            return vector_store

        except Exception as e:
            logger.error(f"ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì‹¤íŒ¨: {e}")
            st.error(f"ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì‹¤íŒ¨: {e}")
            st.code(traceback.format_exc())
            return None

    def _split_text(
        self,
        text: str,
        chunk_size: int = RAGConfig.CHUNK_SIZE,
        overlap: int = RAGConfig.CHUNK_OVERLAP
    ) -> List[str]:
        """í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• 

        Args:
            text: ë¶„í• í•  í…ìŠ¤íŠ¸
            chunk_size: ì²­í¬ í¬ê¸°
            overlap: ì¤‘ì²© í¬ê¸°

        Returns:
            ì²­í¬ ë¦¬ìŠ¤íŠ¸
        """
        chunks = []
        start = 0
        text_length = len(text)

        while start < text_length:
            end = start + chunk_size
            chunk = text[start:end]
            chunks.append(chunk)
            start = end - overlap

        logger.debug(f"í…ìŠ¤íŠ¸ ë¶„í•  ì™„ë£Œ: {len(chunks)}ê°œ ì²­í¬")
        return chunks

    def get_relevant_context(
        self,
        vector_store: SimpleVectorStore,
        query: str,
        k: int = RAGConfig.DEFAULT_K_SEARCH
    ) -> str:
        """ë²¡í„° ìŠ¤í† ì–´ì—ì„œ ì¿¼ë¦¬ì™€ ê´€ë ¨ëœ Kê°œì˜ ì²­í¬ ê²€ìƒ‰

        Args:
            vector_store: ë²¡í„° ìŠ¤í† ì–´
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            k: ê²€ìƒ‰í•  ë¬¸ì„œ ìˆ˜

        Returns:
            ê²€ìƒ‰ëœ ì²­í¬ë“¤ì„ ì—°ê²°í•œ ì»¨í…ìŠ¤íŠ¸
        """
        if vector_store is None:
            logger.warning("ë²¡í„° ìŠ¤í† ì–´ê°€ ì—†ì–´ ë¹ˆ ì»¨í…ìŠ¤íŠ¸ ë°˜í™˜")
            return ""

        try:
            docs = vector_store.similarity_search(query, k=k)
            context = "\n---\n".join(docs)
            logger.debug(f"ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì™„ë£Œ: {len(docs)}ê°œ ì²­í¬, {len(context)} ë¬¸ì")
            return context

        except Exception as e:
            logger.error(f"ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            st.warning(f"ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return ""

    def analyze_policy_alignment(
        self,
        vector_store: Optional[SimpleVectorStore] = None,
        full_text: str = ""
    ) -> AuditEvidence:
        """[RAG ì ìš©] êµ­ë‚´ì™¸ ì •ì±… ë¶€í•©ì„± AI ë¶„ì„

        Args:
            vector_store: RAGìš© ë²¡í„° ìŠ¤í† ì–´ (ì„ íƒ)
            full_text: ì „ì²´ í…ìŠ¤íŠ¸ (fallback)

        Returns:
            ì •ì±… ë¶€í•©ì„± ì‹¬ì‚¬ ê²°ê³¼
        """
        # RAG: ê´€ë ¨ì„± ë†’ì€ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰
        if vector_store:
            query = "êµ­ë‚´ì™¸ ì •ì±… ë¶€í•©ì„±, SDGs, ìˆ˜ì›êµ­ ê°œë°œ ì •ì±…, í•œêµ­ ì •ë¶€ CPS, ì½”ì´ì¹´ ì¤‘ê¸° ì „ëµ, íƒ€ ê³µì—¬ê¸°ê´€ ì§€ì› í˜„í™©, ODA"
            context = self.get_relevant_context(
                vector_store,
                query,
                k=RAGConfig.TOP_K_DOCUMENTS
            )
        else:
            context = full_text[:RAGConfig.MAX_CONTEXT_LENGTH] if full_text else ""

        if not context:
            context = "ë³´ê³ ì„œì—ì„œ ê´€ë ¨ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            logger.warning("ì •ì±…ë¶€í•©ì„± ë¶„ì„ìš© ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ")

        prompt = self._build_policy_alignment_prompt(context)

        try:
            response = self.model.generate_content(prompt)
            result = self._parse_and_validate_response(
                response.text,
                required_keys=['total_score', 'detailed_scores']
            )

            logger.info(f"ì •ì±…ë¶€í•©ì„± ë¶„ì„ ì™„ë£Œ: {result.get('total_score', 0)}ì ")
            return self._create_audit_evidence(
                result,
                max_score=AuditConfig.POLICY_ALIGNMENT_MAX_SCORE
            )

        except json.JSONDecodeError as e:
            logger.error(f"ì •ì±…ë¶€í•©ì„± ë¶„ì„ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            st.error(f"ì •ì±…ë¶€í•©ì„± ë¶„ì„ ê²°ê³¼ íŒŒì‹± ì‹¤íŒ¨: {e}")
            return AuditEvidence.create_failed(
                AuditConfig.POLICY_ALIGNMENT_MAX_SCORE,
                f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}"
            )
        except Exception as e:
            logger.error(f"ì •ì±…ë¶€í•©ì„± ë¶„ì„ ì˜¤ë¥˜: {e}")
            st.error(f"ì •ì±…ë¶€í•©ì„± ë¶„ì„ ì˜¤ë¥˜: {e}")
            return AuditEvidence.create_failed(
                AuditConfig.POLICY_ALIGNMENT_MAX_SCORE,
                str(e)
            )

    def analyze_implementation_readiness(
        self,
        vector_store: Optional[SimpleVectorStore] = None,
        full_text: str = ""
    ) -> AuditEvidence:
        """[RAG ì ìš©] ì‚¬ì—… ì¶”ì§„ ì—¬ê±´ AI ë¶„ì„

        Args:
            vector_store: RAGìš© ë²¡í„° ìŠ¤í† ì–´ (ì„ íƒ)
            full_text: ì „ì²´ í…ìŠ¤íŠ¸ (fallback)

        Returns:
            ì¶”ì§„ ì—¬ê±´ ì‹¬ì‚¬ ê²°ê³¼
        """
        if vector_store:
            query = "ì‚¬ì—… ì¶”ì§„ ì—¬ê±´, ìˆ˜ì›êµ­ ì¶”ì§„ì²´ê³„, êµ­ë‚´ ì¶”ì§„ì²´ê³„, ì‚¬ì—… ì¶”ì§„ì „ëµ, ë¦¬ìŠ¤í¬ ê´€ë¦¬, ì„±ê³¼ê´€ë¦¬, ì˜ˆì‚°, ì¼ì •"
            context = self.get_relevant_context(
                vector_store,
                query,
                k=RAGConfig.TOP_K_DOCUMENTS
            )
        else:
            context = full_text[:RAGConfig.MAX_CONTEXT_LENGTH] if full_text else ""

        if not context:
            context = "ë³´ê³ ì„œì—ì„œ ê´€ë ¨ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            logger.warning("ì¶”ì§„ì—¬ê±´ ë¶„ì„ìš© ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ")

        prompt = self._build_implementation_readiness_prompt(context)

        try:
            response = self.model.generate_content(prompt)
            result = self._parse_and_validate_response(
                response.text,
                required_keys=['total_score', 'detailed_scores']
            )

            logger.info(f"ì¶”ì§„ì—¬ê±´ ë¶„ì„ ì™„ë£Œ: {result.get('total_score', 0)}ì ")
            return self._create_audit_evidence(
                result,
                max_score=AuditConfig.IMPLEMENTATION_READINESS_MAX_SCORE
            )

        except json.JSONDecodeError as e:
            logger.error(f"ì¶”ì§„ì—¬ê±´ ë¶„ì„ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            st.error(f"ì¶”ì§„ì—¬ê±´ ë¶„ì„ ê²°ê³¼ íŒŒì‹± ì‹¤íŒ¨: {e}")
            return AuditEvidence.create_failed(
                AuditConfig.IMPLEMENTATION_READINESS_MAX_SCORE,
                f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}"
            )
        except Exception as e:
            logger.error(f"ì¶”ì§„ì—¬ê±´ ë¶„ì„ ì˜¤ë¥˜: {e}")
            st.error(f"ì¶”ì§„ì—¬ê±´ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return AuditEvidence.create_failed(
                AuditConfig.IMPLEMENTATION_READINESS_MAX_SCORE,
                str(e)
            )

    def _build_policy_alignment_prompt(self, context: str) -> str:
        """ì •ì±… ë¶€í•©ì„± ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        return f"""ë‹¹ì‹ ì€ KOICA ì‚¬ì—… ì‹¬ì‚¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ë³´ê³ ì„œ ë°œì·Œ ë‚´ìš©ì„ 'êµ­ë‚´ì™¸ ì •ì±… ë¶€í•©ì„±' ê¸°ì¤€ìœ¼ë¡œ í‰ê°€í•˜ì„¸ìš”.

=== í‰ê°€ ê¸°ì¤€ (30ì  ë§Œì ) ===
1. SDGsì™€ì˜ ì—°ê´€ì„± (10ì )
2. ìˆ˜ì›êµ­ ì •ì±… ë¶€í•©ì„± (5ì )
3. í•œêµ­ ì •ë¶€ CPS ë° êµ­ì •ê³¼ì œ ì—°ê³„ (5ì )
4. ì½”ì´ì¹´ ì¤‘ê¸°ì „ëµ ë¶€í•©ì„± (5ì )
5. íƒ€ ê³µì—¬ê¸°ê´€ ì¤‘ë³µ ë¶„ì„ (5ì )

=== ë³´ê³ ì„œ ë°œì·Œ ë‚´ìš© ===
{context[:RAGConfig.MAX_CONTEXT_LENGTH]}

=== ì¶œë ¥ í˜•ì‹ (JSON) ===
{{
  "total_score": 0-30 ì‚¬ì´ ì •ìˆ˜,
  "detailed_scores": [
    {{"item": "SDGs", "score": 0-10, "max_score": 10, "reason": "SDGs ì—°ê´€ì„±ì— ëŒ€í•œ í‰ê°€ ê·¼ê±°"}},
    {{"item": "ìˆ˜ì›êµ­ ì •ì±…", "score": 0-5, "max_score": 5, "reason": "ìˆ˜ì›êµ­ ì •ì±… ë¶€í•©ì„±ì— ëŒ€í•œ í‰ê°€ ê·¼ê±°"}},
    {{"item": "CPS/êµ­ì •ê³¼ì œ", "score": 0-5, "max_score": 5, "reason": "CPS/êµ­ì •ê³¼ì œ ì—°ê³„ì„±ì— ëŒ€í•œ í‰ê°€ ê·¼ê±°"}},
    {{"item": "ì½”ì´ì¹´ ì „ëµ", "score": 0-5, "max_score": 5, "reason": "ì½”ì´ì¹´ ì¤‘ê¸°ì „ëµ ë¶€í•©ì„±ì— ëŒ€í•œ í‰ê°€ ê·¼ê±°"}},
    {{"item": "íƒ€ ê³µì—¬ê¸°ê´€", "score": 0-5, "max_score": 5, "reason": "íƒ€ ê³µì—¬ê¸°ê´€ ì¤‘ë³µ ë¶„ì„ì— ëŒ€í•œ í‰ê°€ ê·¼ê±°"}}
  ],
  "reasoning": "ì ìˆ˜ ì‚°ì • ë…¼ë¦¬ ìƒì„¸ ì„¤ëª…",
  "strengths": ["ë°œê²¬ëœ ëª¨ë“  ê°•ì ì„ ë‚˜ì—´"],
  "weaknesses": ["ë°œê²¬ëœ ëª¨ë“  ì•½ì ì„ ë‚˜ì—´"],
  "recommendations": ["í•„ìš”í•œ ëª¨ë“  ê°œì„ ì•ˆì„ ë‚˜ì—´"]
}}

**ì£¼ì˜**: strengths, weaknesses, recommendationsëŠ” ê°ê° ë°œê²¬ëœ ëª¨ë“  ë‚´ìš©ì„ ë¹ ì§ì—†ì´ ë‚˜ì—´í•´ì£¼ì„¸ìš”.
JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”."""

    def _build_implementation_readiness_prompt(self, context: str) -> str:
        """ì¶”ì§„ ì—¬ê±´ ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        return f"""ë‹¹ì‹ ì€ KOICA ì‚¬ì—… ì‹¬ì‚¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ë³´ê³ ì„œ ë°œì·Œ ë‚´ìš©ì„ 'ì‚¬ì—… ì¶”ì§„ ì—¬ê±´' ê¸°ì¤€ìœ¼ë¡œ í‰ê°€í•˜ì„¸ìš”.

=== í‰ê°€ ê¸°ì¤€ (70ì  ë§Œì ) ===
1. ìˆ˜ì›êµ­ ì¶”ì§„ì²´ê³„ (20ì )
2. êµ­ë‚´ ì¶”ì§„ì²´ê³„ (15ì )
3. ì‚¬ì—… ì¶”ì§„ì „ëµ (15ì )
4. ë¦¬ìŠ¤í¬ ê´€ë¦¬ (10ì )
5. ì„±ê³¼ê´€ë¦¬ (10ì )

=== ë³´ê³ ì„œ ë°œì·Œ ë‚´ìš© ===
{context[:RAGConfig.MAX_CONTEXT_LENGTH]}

=== ì¶œë ¥ í˜•ì‹ (JSON) ===
{{
  "total_score": 0-70 ì‚¬ì´ ì •ìˆ˜,
  "detailed_scores": [
    {{"item": "ìˆ˜ì›êµ­ ì¶”ì§„ì²´ê³„", "score": 0-20, "max_score": 20, "reason": "í‰ê°€ ê·¼ê±°"}},
    {{"item": "êµ­ë‚´ ì¶”ì§„ì²´ê³„", "score": 0-15, "max_score": 15, "reason": "í‰ê°€ ê·¼ê±°"}},
    {{"item": "ì‚¬ì—… ì¶”ì§„ì „ëµ", "score": 0-15, "max_score": 15, "reason": "í‰ê°€ ê·¼ê±°"}},
    {{"item": "ë¦¬ìŠ¤í¬ ê´€ë¦¬", "score": 0-10, "max_score": 10, "reason": "í‰ê°€ ê·¼ê±°"}},
    {{"item": "ì„±ê³¼ê´€ë¦¬", "score": 0-10, "max_score": 10, "reason": "í‰ê°€ ê·¼ê±°"}}
  ],
  "reasoning": "ì ìˆ˜ ì‚°ì • ë…¼ë¦¬ ìƒì„¸ ì„¤ëª…",
  "strengths": ["ë°œê²¬ëœ ëª¨ë“  ê°•ì ì„ ë‚˜ì—´"],
  "weaknesses": ["ë°œê²¬ëœ ëª¨ë“  ì•½ì ì„ ë‚˜ì—´"],
  "recommendations": ["í•„ìš”í•œ ëª¨ë“  ê°œì„ ì•ˆì„ ë‚˜ì—´"]
}}

**ì£¼ì˜**: strengths, weaknesses, recommendationsëŠ” ê°ê° ë°œê²¬ëœ ëª¨ë“  ë‚´ìš©ì„ ë¹ ì§ì—†ì´ ë‚˜ì—´í•´ì£¼ì„¸ìš”.
JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”."""

    @staticmethod
    def _parse_and_validate_response(
        response_text: str,
        required_keys: List[str]
    ) -> Dict[str, Any]:
        """API ì‘ë‹µ íŒŒì‹± ë° ê²€ì¦

        Args:
            response_text: JSON ì‘ë‹µ í…ìŠ¤íŠ¸
            required_keys: í•„ìˆ˜ í‚¤ ë¦¬ìŠ¤íŠ¸

        Returns:
            íŒŒì‹±ëœ ë”•ì…”ë„ˆë¦¬

        Raises:
            json.JSONDecodeError: JSON íŒŒì‹± ì‹¤íŒ¨
            KeyError: í•„ìˆ˜ í‚¤ ëˆ„ë½
        """
        result = json.loads(response_text)

        # í•„ìˆ˜ í‚¤ ê²€ì¦
        for key in required_keys:
            if key not in result:
                raise KeyError(f"í•„ìˆ˜ í‚¤ '{key}'ê°€ ì‘ë‹µì— ì—†ìŠµë‹ˆë‹¤")

        return result

    @staticmethod
    def _create_audit_evidence(result: Dict[str, Any], max_score: int) -> AuditEvidence:
        """API ì‘ë‹µì—ì„œ AuditEvidence ê°ì²´ ìƒì„±

        Args:
            result: íŒŒì‹±ëœ API ì‘ë‹µ
            max_score: ë§Œì 

        Returns:
            AuditEvidence ê°ì²´
        """
        score = result.get('total_score', 0)
        return AuditEvidence(
            score=score,
            max_score=max_score,
            percentage=round(score / max_score * 100, 1) if max_score > 0 else 0.0,
            detailed_scores=result.get('detailed_scores', []),
            reasoning=result.get('reasoning', ''),
            strengths=result.get('strengths', []),
            weaknesses=result.get('weaknesses', []),
            recommendations=result.get('recommendations', [])
        )

    def conduct_audit(self, full_text: str) -> Optional[Dict[str, Any]]:
        """ì „ì²´ ì‹¬ì‚¬ ìˆ˜í–‰ (RAG ê¸°ë°˜)

        Args:
            full_text: ì‹¬ì‚¬í•  ì „ì²´ í…ìŠ¤íŠ¸

        Returns:
            ì‹¬ì‚¬ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ ë˜ëŠ” None
        """
        start_time = datetime.now()
        logger.info("ì‹¬ì‚¬ ì‹œì‘")

        try:
            # 1. ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì‹œë„
            vector_store = self.create_vector_store(full_text)

            if not vector_store:
                st.warning("âš ï¸ RAG ëª¨ë“œ ì‹¤íŒ¨. ì „ì²´ í…ìŠ¤íŠ¸ ì•ë¶€ë¶„ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.")
                logger.warning("RAG ëª¨ë“œ ì‹¤íŒ¨, fallbackìœ¼ë¡œ ì§„í–‰")

            # 2. ì •ì±… ë¶€í•©ì„± ë¶„ì„
            with st.spinner("ğŸŒ ì •ì±… ë¶€í•©ì„± ë¶„ì„ ì¤‘..."):
                policy_result = self.analyze_policy_alignment(vector_store, full_text)

            # 3. ì¶”ì§„ ì—¬ê±´ ë¶„ì„
            with st.spinner("ğŸ—ï¸ ì‚¬ì—… ì¶”ì§„ ì—¬ê±´ ë¶„ì„ ì¤‘..."):
                impl_result = self.analyze_implementation_readiness(vector_store, full_text)

            # 4. ê²°ê³¼ ì¢…í•©
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()

            results = {
                "ì´ì ": policy_result.score + impl_result.score,
                "ì •ì±…ë¶€í•©ì„±": {
                    "ì ìˆ˜": policy_result.score,
                    "ë§Œì ": policy_result.max_score,
                    "ë°±ë¶„ìœ¨": policy_result.percentage,
                    "ì„¸ë¶€ì ìˆ˜": policy_result.detailed_scores,
                    "ê°•ì ": policy_result.strengths,
                    "ì•½ì ": policy_result.weaknesses,
                    "ì œì•ˆ": policy_result.recommendations
                },
                "ì¶”ì§„ì—¬ê±´": {
                    "ì ìˆ˜": impl_result.score,
                    "ë§Œì ": impl_result.max_score,
                    "ë°±ë¶„ìœ¨": impl_result.percentage,
                    "ì„¸ë¶€ì ìˆ˜": impl_result.detailed_scores,
                    "ê°•ì ": impl_result.strengths,
                    "ì•½ì ": impl_result.weaknesses,
                    "ì œì•ˆ": impl_result.recommendations
                },
                "ë¶„ì„ì‹œê°„": f"{duration:.1f}ì´ˆ",
                "RAG_ì‚¬ìš©": vector_store is not None
            }

            logger.info(f"ì‹¬ì‚¬ ì™„ë£Œ: ì´ì  {results['ì´ì ']}/100, ì†Œìš”ì‹œê°„ {duration:.1f}ì´ˆ")
            return results

        except Exception as e:
            logger.error(f"ì‹¬ì‚¬ ìˆ˜í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
            logger.error(traceback.format_exc())
            st.error(f"âŒ ì‹¬ì‚¬ ìˆ˜í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
            # í”„ë¡œë•ì…˜ì—ì„œëŠ” ìƒì„¸ ìŠ¤íƒíŠ¸ë ˆì´ìŠ¤ë¥¼ ìˆ¨ê¹€
            # st.code(traceback.format_exc())
            return None
