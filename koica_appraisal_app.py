#!/usr/bin/env python3
"""
KOICA ì‚¬ì—… ì˜ˆë¹„ì¡°ì‚¬ ì‹¬ì‚¬ ì‹œìŠ¤í…œ - Streamlit Web App
(RAG, JSON ëª¨ë“œ, ì„¸ë¶€ ì±„ì  ê¸°ëŠ¥ ì ìš© ë²„ì „ - ì„ë² ë”© ì˜¤ë¥˜ ìˆ˜ì •)
"""

import streamlit as st
import os
import io
import json
import traceback
from datetime import datetime
from typing import Dict, List, Any, Optional
from dataclasses import dataclass

# --- í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„í¬íŠ¸ ---
import PyPDF2
import google.generativeai as genai
from google.generativeai.types import GenerationConfig
from langchain_community.vectorstores import FAISS
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_google_genai import GoogleGenerativeAIEmbeddings

# --- í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(
    page_title="KOICA ì‹¬ì‚¬ ë¶„ì„ ë„êµ¬ v2 (RAG)",
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- CSS ìŠ¤íƒ€ì¼ ---
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        text-align: center;
        color: #666;
        margin-bottom: 2rem;
    }
    .score-box {
        padding: 20px;
        border-radius: 10px;
        margin: 20px 0;
        text-align: center;
    }
    .good-score { background-color: #d4edda; border: 2px solid #28a745; }
    .average-score { background-color: #fff3cd; border: 2px solid #ffc107; }
    .poor-score { background-color: #f8d7da; border: 2px solid #dc3545; }
    .disclaimer {
        background-color: #fff3cd;
        border-left: 5px solid #ffc107;
        padding: 15px;
        margin: 20px 0;
        border-radius: 5px;
    }
</style>
""", unsafe_allow_html=True)


# --- ë°ì´í„° í´ë˜ìŠ¤ ---
@dataclass
class AuditEvidence:
    """ì‹¬ì‚¬ ê·¼ê±° ë°ì´í„° í´ë˜ìŠ¤"""
    score: int
    max_score: int
    percentage: float
    detailed_scores: List[Dict[str, Any]]
    reasoning: str
    strengths: List[str]
    weaknesses: List[str]
    recommendations: List[str]


class KOICAAuditorStreamlit:
    """KOICA ì‹¬ì‚¬ ì‹œìŠ¤í…œ - RAG ì ìš© ë²„ì „"""
    
    def __init__(self, api_key: Optional[str] = None):
        """ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        self.audit_criteria = {
            "ì •ì±…ë¶€í•©ì„±": {
                "ë§Œì ": 30,
                "í•­ëª©": ["SDGs ì—°ê´€ì„±", "ìˆ˜ì›êµ­ ì •ì±…", "CPS/êµ­ì •ê³¼ì œ", "ì½”ì´ì¹´ ì „ëµ", "íƒ€ ê³µì—¬ê¸°ê´€"]
            },
            "ì¶”ì§„ì—¬ê±´": {
                "ë§Œì ": 70,
                "í•­ëª©": ["ìˆ˜ì›êµ­ ì¶”ì§„ì²´ê³„", "êµ­ë‚´ ì¶”ì§„ì²´ê³„", "ì‚¬ì—… ì¶”ì§„ì „ëµ", "ë¦¬ìŠ¤í¬ ê´€ë¦¬", "ì„±ê³¼ê´€ë¦¬"]
            }
        }
        
        if not api_key:
            raise ValueError("Gemini API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤")
        
        try:
            # 1. Gemini ì„¤ì •
            genai.configure(api_key=api_key)
            
            # 2. JSON ëª¨ë“œ ì„¤ì •
            self.json_config = GenerationConfig(response_mime_type="application/json")
            
            # 3. Gemini ëª¨ë¸ ì´ˆê¸°í™” (JSON ëª¨ë“œ ì ìš©)
            self.model = genai.GenerativeModel(
                'gemini-2.0-flash-exp',
                generation_config=self.json_config
            )
            
            # 4. RAGë¥¼ ìœ„í•œ ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” (ìˆ˜ì •ë¨)
            # task_typeì„ ëª…ì‹œì ìœ¼ë¡œ ì§€ì •í•˜ì—¬ ë©”íƒ€ë°ì´í„° ì˜¤ë¥˜ ë°©ì§€
            self.embeddings = GoogleGenerativeAIEmbeddings(
                model="models/text-embedding-004",
                google_api_key=api_key,
                task_type="retrieval_document"  # ë¬¸ì„œ ê²€ìƒ‰ìš©ìœ¼ë¡œ ëª…ì‹œ
            )
            
        except Exception as e:
            raise Exception(f"Gemini API ë˜ëŠ” ì„ë² ë”© ëª¨ë¸ ì—°ê²° ì‹¤íŒ¨: {e}")
    
    def extract_text_from_pdf(self, pdf_file) -> str:
        """PDFì—ì„œ ì „ì²´ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        try:
            pdf_reader = PyPDF2.PdfReader(pdf_file)
            full_text = ""
            total_pages = len(pdf_reader.pages)
            
            progress_bar = st.progress(0, text="ğŸ“„ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘...")
            
            for page_num, page in enumerate(pdf_reader.pages, 1):
                try:
                    full_text += page.extract_text() + "\n"
                    progress = page_num / total_pages
                    progress_bar.progress(progress, text=f"í˜ì´ì§€ ì¶”ì¶œ ì¤‘: {page_num}/{total_pages}")
                except Exception:
                    st.warning(f"í˜ì´ì§€ {page_num} ì²˜ë¦¬ ì˜¤ë¥˜ (ê±´ë„ˆëœ€)")
            
            progress_bar.empty()
            return full_text
            
        except Exception as e:
            raise Exception(f"PDF ì²˜ë¦¬ ì˜¤ë¥˜: {e}")

    def create_vector_store(self, full_text: str) -> Optional[FAISS]:
        """í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë‚˜ëˆ„ê³  ë²¡í„° ìŠ¤í† ì–´(FAISS) ìƒì„± (ì˜¤ë¥˜ ìˆ˜ì • ë²„ì „)"""
        if not full_text:
            st.error("ì¶”ì¶œëœ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # 1. í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• 
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1500,
            chunk_overlap=200,
            separators=["\n\n", "\n", "##", "#", " ", ""]
        )
        chunks = text_splitter.split_text(full_text)
        
        if not chunks:
            st.error("í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë‚˜ëˆŒ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        st.info(f"ğŸ“¦ ì´ {len(chunks)}ê°œ ì²­í¬ ìƒì„±ë¨. ì„ë² ë”© ì¤‘...")
        
        try:
            # 2. ë²¡í„° ìŠ¤í† ì–´ ìƒì„± (ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì•ˆì •ì„± í–¥ìƒ)
            with st.spinner("ì„ë² ë”© ìƒì„± ë° ë²¡í„° ì¸ë±ì‹± ì¤‘... (ë¬¸ì„œ í¬ê¸°ì— ë”°ë¼ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)"):
                # í° ë¬¸ì„œì˜ ê²½ìš° ë°°ì¹˜ ì²˜ë¦¬
                batch_size = 50  # í•œ ë²ˆì— 50ê°œì”© ì²˜ë¦¬
                
                if len(chunks) <= batch_size:
                    # ì‘ì€ ë¬¸ì„œëŠ” í•œ ë²ˆì— ì²˜ë¦¬
                    vector_store = FAISS.from_texts(chunks, self.embeddings)
                else:
                    # í° ë¬¸ì„œëŠ” ë°°ì¹˜ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬
                    vector_store = None
                    progress_bar = st.progress(0)
                    
                    for i in range(0, len(chunks), batch_size):
                        batch = chunks[i:i+batch_size]
                        progress = (i + len(batch)) / len(chunks)
                        progress_bar.progress(progress, text=f"ì„ë² ë”© ì§„í–‰ ì¤‘: {i+len(batch)}/{len(chunks)}")
                        
                        if vector_store is None:
                            # ì²« ë°°ì¹˜ë¡œ ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™”
                            vector_store = FAISS.from_texts(batch, self.embeddings)
                        else:
                            # ê¸°ì¡´ ë²¡í„° ìŠ¤í† ì–´ì— ì¶”ê°€
                            temp_store = FAISS.from_texts(batch, self.embeddings)
                            vector_store.merge_from(temp_store)
                    
                    progress_bar.empty()
            
            st.success("âœ… ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ!")
            return vector_store
            
        except Exception as e:
            st.error(f"ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì‹¤íŒ¨: {e}")
            st.code(traceback.format_exc())
            
            # ëŒ€ì²´ ë°©ì•ˆ ì œì‹œ
            st.warning("ğŸ’¡ **ëŒ€ì²´ ë°©ì•ˆ**: RAG ì—†ì´ ì „ì²´ í…ìŠ¤íŠ¸ì˜ ì•ë¶€ë¶„ë§Œ ë¶„ì„í•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
            if st.button("RAG ì—†ì´ ê³„ì† ì§„í–‰", key="fallback_no_rag"):
                st.session_state['use_fallback'] = True
            
            return None

    def get_relevant_context(self, vector_store: FAISS, query: str, k: int = 10) -> str:
        """ë²¡í„° ìŠ¤í† ì–´ì—ì„œ ì¿¼ë¦¬ì™€ ê´€ë ¨ëœ Kê°œì˜ ì²­í¬ ê²€ìƒ‰"""
        if vector_store is None:
            return ""
        try:
            docs = vector_store.similarity_search(query, k=k)
            context = "\n---\n".join([doc.page_content for doc in docs])
            return context
        except Exception as e:
            st.warning(f"ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return ""

    def analyze_policy_alignment(self, vector_store: FAISS = None, full_text: str = "") -> AuditEvidence:
        """[RAG ì ìš©] êµ­ë‚´ì™¸ ì •ì±… ë¶€í•©ì„± AI ë¶„ì„"""
        
        # 1. RAG: ê´€ë ¨ì„± ë†’ì€ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰
        if vector_store:
            query = "êµ­ë‚´ì™¸ ì •ì±… ë¶€í•©ì„±, SDGs, ìˆ˜ì›êµ­ ê°œë°œ ì •ì±…, í•œêµ­ ì •ë¶€ CPS, ì½”ì´ì¹´ ì¤‘ê¸° ì „ëµ, íƒ€ ê³µì—¬ê¸°ê´€ ì§€ì› í˜„í™©, ODA"
            context = self.get_relevant_context(vector_store, query)
        else:
            # RAG ì‹¤íŒ¨ ì‹œ ì „ì²´ í…ìŠ¤íŠ¸ì˜ ì•ë¶€ë¶„ ì‚¬ìš©
            context = full_text[:30000] if full_text else ""
        
        if not context:
            context = "ë³´ê³ ì„œì—ì„œ ê´€ë ¨ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # 2. ì„¸ë¶€ ì±„ì  ê¸°ì¤€ í”„ë¡¬í”„íŠ¸ (JSON ëª¨ë“œ)
        prompt = f"""ë‹¹ì‹ ì€ KOICA ì‚¬ì—… ì‹¬ì‚¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ë³´ê³ ì„œ ë°œì·Œ ë‚´ìš©ì„ 'êµ­ë‚´ì™¸ ì •ì±… ë¶€í•©ì„±' ê¸°ì¤€ìœ¼ë¡œ í‰ê°€í•˜ì„¸ìš”.

=== í‰ê°€ ê¸°ì¤€ (30ì  ë§Œì ) ===
1. SDGsì™€ì˜ ì—°ê´€ì„± (10ì )
2. ìˆ˜ì›êµ­ ì •ì±… ë¶€í•©ì„± (5ì )
3. í•œêµ­ ì •ë¶€ CPS ë° êµ­ì •ê³¼ì œ ì—°ê³„ (5ì )
4. ì½”ì´ì¹´ ì¤‘ê¸°ì „ëµ ë¶€í•©ì„± (5ì )
5. íƒ€ ê³µì—¬ê¸°ê´€ ì¤‘ë³µ ë¶„ì„ (5ì )

=== ë³´ê³ ì„œ ë°œì·Œ ë‚´ìš© ===
{context[:30000]}

=== ì¶œë ¥ í˜•ì‹ (JSON) ===
{{
  "total_score": 0-30 ì‚¬ì´ ì •ìˆ˜,
  "detailed_scores": [
    {{"item": "SDGs", "score": 0-10, "max_score": 10, "reason": "SDGs ì—°ê´€ì„±ì— ëŒ€í•œ í‰ê°€ ê·¼ê±°"}},
    {{"item": "ìˆ˜ì›êµ­ ì •ì±…", "score": 0-5, "max_score": 5, "reason": "ìˆ˜ì›êµ­ ì •ì±… ë¶€í•©ì„±ì— ëŒ€í•œ í‰ê°€ ê·¼ê±°"}},
    {{"item": "CPS/êµ­ì •ê³¼ì œ", "score": 0-5, "max_score": 5, "reason": "CPS/êµ­ì •ê³¼ì œ ì—°ê³„ì„±ì— ëŒ€í•œ í‰ê°€ ê·¼ê±°"}},
    {{"item": "ì½”ì´ì¹´ ì „ëµ", "score": 0-5, "max_score": 5, "reason": "ì½”ì´ì¹´ ì¤‘ê¸°ì „ëµ ë¶€í•©ì„±ì— ëŒ€í•œ í‰ê°€ ê·¼ê±°"}},
    {{"item": "íƒ€ ê³µì—¬ê¸°ê´€", "score": 0-5, "max_score": 5, "reason": "íƒ€ ê³µì—¬ê¸°ê´€ ì¤‘ë³µ ë¶„ì„ì— ëŒ€í•œ í‰ê°€ ê·¼ê±°"}}
  ],
  "reasoning": "ì ìˆ˜ ì‚°ì • ë…¼ë¦¬ ìƒì„¸ ì„¤ëª…",
  "strengths": ["ê°•ì 1", "ê°•ì 2"],
  "weaknesses": ["ì•½ì 1", "ì•½ì 2"],
  "recommendations": ["ê°œì„ ì•ˆ1", "ê°œì„ ì•ˆ2"]
}}

JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”."""

        try:
            response = self.model.generate_content(prompt)
            result = json.loads(response.text)
            
            return AuditEvidence(
                score=result['total_score'],
                max_score=30,
                percentage=round(result['total_score'] / 30 * 100, 1),
                detailed_scores=result.get('detailed_scores', []),
                reasoning=result.get('reasoning', ''),
                strengths=result.get('strengths', []),
                weaknesses=result.get('weaknesses', []),
                recommendations=result.get('recommendations', [])
            )
        except Exception as e:
            st.error(f"ì •ì±…ë¶€í•©ì„± ë¶„ì„ ì˜¤ë¥˜: {e}")
            return AuditEvidence(0, 30, 0.0, [], f"ë¶„ì„ ì‹¤íŒ¨: {e}", [], [], [])

    def analyze_implementation_readiness(self, vector_store: FAISS = None, full_text: str = "") -> AuditEvidence:
        """[RAG ì ìš©] ì‚¬ì—… ì¶”ì§„ ì—¬ê±´ AI ë¶„ì„"""
        
        if vector_store:
            query = "ì‚¬ì—… ì¶”ì§„ ì—¬ê±´, ìˆ˜ì›êµ­ ì¶”ì§„ì²´ê³„, êµ­ë‚´ ì¶”ì§„ì²´ê³„, ì‚¬ì—… ì¶”ì§„ì „ëµ, ë¦¬ìŠ¤í¬ ê´€ë¦¬, ì„±ê³¼ê´€ë¦¬, ì˜ˆì‚°, ì¼ì •"
            context = self.get_relevant_context(vector_store, query)
        else:
            context = full_text[:30000] if full_text else ""
        
        if not context:
            context = "ë³´ê³ ì„œì—ì„œ ê´€ë ¨ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        prompt = f"""ë‹¹ì‹ ì€ KOICA ì‚¬ì—… ì‹¬ì‚¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ë³´ê³ ì„œ ë°œì·Œ ë‚´ìš©ì„ 'ì‚¬ì—… ì¶”ì§„ ì—¬ê±´' ê¸°ì¤€ìœ¼ë¡œ í‰ê°€í•˜ì„¸ìš”.

=== í‰ê°€ ê¸°ì¤€ (70ì  ë§Œì ) ===
1. ìˆ˜ì›êµ­ ì¶”ì§„ì²´ê³„ (20ì )
2. êµ­ë‚´ ì¶”ì§„ì²´ê³„ (15ì )
3. ì‚¬ì—… ì¶”ì§„ì „ëµ (15ì )
4. ë¦¬ìŠ¤í¬ ê´€ë¦¬ (10ì )
5. ì„±ê³¼ê´€ë¦¬ (10ì )

=== ë³´ê³ ì„œ ë°œì·Œ ë‚´ìš© ===
{context[:30000]}

=== ì¶œë ¥ í˜•ì‹ (JSON) ===
{{
  "total_score": 0-70 ì‚¬ì´ ì •ìˆ˜,
  "detailed_scores": [
    {{"item": "ìˆ˜ì›êµ­ ì¶”ì§„ì²´ê³„", "score": 0-20, "max_score": 20, "reason": "í‰ê°€ ê·¼ê±°"}},
    {{"item": "êµ­ë‚´ ì¶”ì§„ì²´ê³„", "score": 0-15, "max_score": 15, "reason": "í‰ê°€ ê·¼ê±°"}},
    {{"item": "ì‚¬ì—… ì¶”ì§„ì „ëµ", "score": 0-15, "max_score": 15, "reason": "í‰ê°€ ê·¼ê±°"}},
    {{"item": "ë¦¬ìŠ¤í¬ ê´€ë¦¬", "score": 0-10, "max_score": 10, "reason": "í‰ê°€ ê·¼ê±°"}},
    {{"item": "ì„±ê³¼ê´€ë¦¬", "score": 0-10, "max_score": 10, "reason": "í‰ê°€ ê·¼ê±°"}}
  ],
  "reasoning": "ì ìˆ˜ ì‚°ì • ë…¼ë¦¬ ìƒì„¸ ì„¤ëª…",
  "strengths": ["ê°•ì 1", "ê°•ì 2"],
  "weaknesses": ["ì•½ì 1", "ì•½ì 2"],
  "recommendations": ["ê°œì„ ì•ˆ1", "ê°œì„ ì•ˆ2"]
}}

JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”."""

        try:
            response = self.model.generate_content(prompt)
            result = json.loads(response.text)
            
            return AuditEvidence(
                score=result['total_score'],
                max_score=70,
                percentage=round(result['total_score'] / 70 * 100, 1),
                detailed_scores=result.get('detailed_scores', []),
                reasoning=result.get('reasoning', ''),
                strengths=result.get('strengths', []),
                weaknesses=result.get('weaknesses', []),
                recommendations=result.get('recommendations', [])
            )
        except Exception as e:
            st.error(f"ì¶”ì§„ì—¬ê±´ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return AuditEvidence(0, 70, 0.0, [], f"ë¶„ì„ ì‹¤íŒ¨: {e}", [], [], [])

    def conduct_audit(self, full_text: str) -> Optional[Dict[str, Any]]:
        """ì „ì²´ ì‹¬ì‚¬ ìˆ˜í–‰ (RAG ê¸°ë°˜)"""
        start_time = datetime.now()
        
        try:
            # 1. ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì‹œë„
            vector_store = self.create_vector_store(full_text)
            
            if not vector_store:
                st.warning("âš ï¸ RAG ëª¨ë“œ ì‹¤íŒ¨. ì „ì²´ í…ìŠ¤íŠ¸ ì•ë¶€ë¶„ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.")
            
            # 2. ì •ì±… ë¶€í•©ì„± ë¶„ì„
            with st.spinner("ğŸŒ ì •ì±… ë¶€í•©ì„± ë¶„ì„ ì¤‘..."):
                policy_result = self.analyze_policy_alignment(vector_store, full_text)
            
            # 3. ì¶”ì§„ ì—¬ê±´ ë¶„ì„
            with st.spinner("ğŸ—ï¸ ì‚¬ì—… ì¶”ì§„ ì—¬ê±´ ë¶„ì„ ì¤‘..."):
                impl_result = self.analyze_implementation_readiness(vector_store, full_text)
            
            # 4. ê²°ê³¼ ì¢…í•©
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()
            
            results = {
                "ì´ì ": policy_result.score + impl_result.score,
                "ì •ì±…ë¶€í•©ì„±": {
                    "ì ìˆ˜": policy_result.score,
                    "ë§Œì ": policy_result.max_score,
                    "ë°±ë¶„ìœ¨": policy_result.percentage,
                    "ì„¸ë¶€ì ìˆ˜": policy_result.detailed_scores,
                    "ê°•ì ": policy_result.strengths,
                    "ì•½ì ": policy_result.weaknesses,
                    "ì œì•ˆ": policy_result.recommendations
                },
                "ì¶”ì§„ì—¬ê±´": {
                    "ì ìˆ˜": impl_result.score,
                    "ë§Œì ": impl_result.max_score,
                    "ë°±ë¶„ìœ¨": impl_result.percentage,
                    "ì„¸ë¶€ì ìˆ˜": impl_result.detailed_scores,
                    "ê°•ì ": impl_result.strengths,
                    "ì•½ì ": impl_result.weaknesses,
                    "ì œì•ˆ": impl_result.recommendations
                },
                "ë¶„ì„ì‹œê°„": f"{duration:.1f}ì´ˆ",
                "RAG_ì‚¬ìš©": vector_store is not None
            }
            
            return results
            
        except Exception as e:
            st.error(f"âŒ ì‹¬ì‚¬ ìˆ˜í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
            st.code(traceback.format_exc())
            return None


def display_results(results: Dict[str, Any]):
    """ë¶„ì„ ê²°ê³¼ í‘œì‹œ"""
    # RAG ì‚¬ìš© ì—¬ë¶€ í‘œì‹œ
    if not results.get('RAG_ì‚¬ìš©', False):
        st.warning("âš ï¸ ì´ ë¶„ì„ì€ RAG ì—†ì´ ìˆ˜í–‰ë˜ì—ˆìŠµë‹ˆë‹¤. ì „ì²´ ë¬¸ì„œê°€ ì•„ë‹Œ ì•ë¶€ë¶„ë§Œ ë¶„ì„ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    # ì´ì  í‘œì‹œ
    total_score = results['ì´ì ']
    score_class = "good-score" if total_score >= 80 else "average-score" if total_score >= 60 else "poor-score"
    st.markdown(f"""
    <div class="score-box {score_class}">
        <h2>ì´ì : {total_score} / 100</h2>
        <p>ë¶„ì„ ì‹œê°„: {results['ë¶„ì„ì‹œê°„']}</p>
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown("### ğŸ“‹ í•­ëª©ë³„ í‰ê°€")
    col1, col2 = st.columns(2)
    
    with col1:
        policy = results['ì •ì±…ë¶€í•©ì„±']
        st.markdown("#### ğŸŒ êµ­ë‚´ì™¸ ì •ì±… ë¶€í•©ì„±")
        st.metric("ì ìˆ˜", f"{policy['ì ìˆ˜']}/{policy['ë§Œì ']}", f"{policy['ë°±ë¶„ìœ¨']:.1f}%")
        
        with st.expander("ìƒì„¸ ë¶„ì„ ë³´ê¸°"):
            st.markdown("**ğŸ“Œ ì„¸ë¶€ í•­ëª© í‰ê°€**")
            for item in policy['ì„¸ë¶€ì ìˆ˜']:
                st.markdown(f"**{item['item']} ({item['score']}/{item['max_score']})**")
                st.caption(f"_{item['reason']}_")
            
            st.markdown("---")
            st.markdown("**âœ… ê°•ì **")
            for s in policy['ê°•ì ']:
                st.markdown(f"- {s}")
            st.markdown("**âš ï¸ ì•½ì **")
            for w in policy['ì•½ì ']:
                st.markdown(f"- {w}")
            st.markdown("**ğŸ’¡ ê°œì„  ì œì•ˆ**")
            for r in policy['ì œì•ˆ']:
                st.markdown(f"- {r}")
    
    with col2:
        impl = results['ì¶”ì§„ì—¬ê±´']
        st.markdown("#### ğŸ—ï¸ ì‚¬ì—… ì¶”ì§„ ì—¬ê±´")
        st.metric("ì ìˆ˜", f"{impl['ì ìˆ˜']}/{impl['ë§Œì ']}", f"{impl['ë°±ë¶„ìœ¨']:.1f}%")
        
        with st.expander("ìƒì„¸ ë¶„ì„ ë³´ê¸°"):
            st.markdown("**ğŸ“Œ ì„¸ë¶€ í•­ëª© í‰ê°€**")
            for item in impl['ì„¸ë¶€ì ìˆ˜']:
                st.markdown(f"**{item['item']} ({item['score']}/{item['max_score']})**")
                st.caption(f"_{item['reason']}_")

            st.markdown("---")
            st.markdown("**âœ… ê°•ì **")
            for s in impl['ê°•ì ']:
                st.markdown(f"- {s}")
            st.markdown("**âš ï¸ ì•½ì **")
            for w in impl['ì•½ì ']:
                st.markdown(f"- {w}")
            st.markdown("**ğŸ’¡ ê°œì„  ì œì•ˆ**")
            for r in impl['ì œì•ˆ']:
                st.markdown(f"- {r}")


def generate_report_text(results: Dict[str, Any]) -> str:
    """í…ìŠ¤íŠ¸ ë³´ê³ ì„œ ìƒì„±"""
    lines = []
    lines.append("=" * 80)
    lines.append("KOICA ì‚¬ì—… ì‹¬ì‚¬ ë¶„ì„ ê²°ê³¼ (AI-RAG ê¸°ë°˜ v2)")
    lines.append("=" * 80)
    lines.append(f"ë¶„ì„ ì¼ì‹œ: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M:%S')}")
    lines.append(f"ë¶„ì„ ì‹œê°„: {results['ë¶„ì„ì‹œê°„']}")
    lines.append(f"RAG ì‚¬ìš©: {'ì˜ˆ' if results.get('RAG_ì‚¬ìš©', False) else 'ì•„ë‹ˆì˜¤ (ì „ì²´ í…ìŠ¤íŠ¸ ì•ë¶€ë¶„ë§Œ ë¶„ì„)'}")
    lines.append(f"ì´ì : {results['ì´ì ']} / 100\n")
    
    # ì •ì±… ë¶€í•©ì„±
    policy = results['ì •ì±…ë¶€í•©ì„±']
    lines.append(f"\n[1] êµ­ë‚´ì™¸ ì •ì±… ë¶€í•©ì„± ({policy['ì ìˆ˜']}/{policy['ë§Œì ']})")
    lines.append("-" * 80)
    lines.append("\nì„¸ë¶€ í‰ê°€:")
    for item in policy['ì„¸ë¶€ì ìˆ˜']:
        lines.append(f"  â€¢ {item['item']} ({item['score']}/{item['max_score']})")
        lines.append(f"    â”” ê·¼ê±°: {item['reason']}")
    lines.append("\nê°•ì :")
    for s in policy['ê°•ì ']:
        lines.append(f"  âœ“ {s}")
    lines.append("\nì•½ì :")
    for w in policy['ì•½ì ']:
        lines.append(f"  âœ— {w}")
    lines.append("\nê°œì„  ì œì•ˆ:")
    for r in policy['ì œì•ˆ']:
        lines.append(f"  â†’ {r}")
    
    # ì¶”ì§„ ì—¬ê±´
    impl = results['ì¶”ì§„ì—¬ê±´']
    lines.append(f"\n\n[2] ì‚¬ì—… ì¶”ì§„ ì—¬ê±´ ({impl['ì ìˆ˜']}/{impl['ë§Œì ']})")
    lines.append("-" * 80)
    lines.append("\nì„¸ë¶€ í‰ê°€:")
    for item in impl['ì„¸ë¶€ì ìˆ˜']:
        lines.append(f"  â€¢ {item['item']} ({item['score']}/{item['max_score']})")
        lines.append(f"    â”” ê·¼ê±°: {item['reason']}")
    lines.append("\nê°•ì :")
    for s in impl['ê°•ì ']:
        lines.append(f"  âœ“ {s}")
    lines.append("\nì•½ì :")
    for w in impl['ì•½ì ']:
        lines.append(f"  âœ— {w}")
    lines.append("\nê°œì„  ì œì•ˆ:")
    for r in impl['ì œì•ˆ']:
        lines.append(f"  â†’ {r}")
    
    lines.append("\n\n" + "=" * 80)
    lines.append("ë©´ì±… ì¡°í•­")
    lines.append("=" * 80)
    lines.append("ë³¸ ë¶„ì„ ê²°ê³¼ëŠ” AI ê¸°ë°˜ ì°¸ê³ ìš©ì´ë©°, KOICA ê³µì‹ ì‹¬ì‚¬ ê²°ê³¼ê°€ ì•„ë‹™ë‹ˆë‹¤.")
    lines.append("ì‹¤ì œ ì‹¬ì‚¬ëŠ” ì „ë¬¸ê°€ì˜ ì¢…í•©ì  íŒë‹¨ìœ¼ë¡œ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤.")
    
    return "\n".join(lines)


# ========== ë©”ì¸ ì•± ==========

def main():
    st.markdown('<h1 class="main-header">ğŸš€ KOICA ì‚¬ì—… ì‹¬ì‚¬ ë¶„ì„ ë„êµ¬ (RAG v2)</h1>', unsafe_allow_html=True)
    st.markdown('<p class="sub-header">RAG, JSON ëª¨ë“œ ì ìš© Â· ë¹„ê³µì‹ ê°œì¸ í”„ë¡œì íŠ¸</p>', unsafe_allow_html=True)
    
    # Disclaimer
    st.markdown("""
    <div class="disclaimer">
        <strong>âš ï¸ ì£¼ì˜ì‚¬í•­</strong><br>
        ë³¸ ë„êµ¬ëŠ” <strong>KOICA ê³µì‹ ì„œë¹„ìŠ¤ê°€ ì•„ë‹™ë‹ˆë‹¤</strong>. ê°œì¸ì´ KOICA ì‹¬ì‚¬ ê¸°ì¤€ì„ ì°¸ê³ í•˜ì—¬ ë…ìì ìœ¼ë¡œ ê°œë°œí•œ ë¶„ì„ ë„êµ¬ì…ë‹ˆë‹¤. ë¶„ì„ ê²°ê³¼ëŠ” ì°¸ê³ ìš©ì´ë©°, ê³µì‹ì ì¸ ì‹¬ì‚¬ ê²°ê³¼ì™€ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    </div>
    """, unsafe_allow_html=True)
    
    # API í‚¤ ë¡œë“œ
    api_key = None
    try:
        api_key = st.secrets["GEMINI_API_KEY"]
    except:
        api_key = os.getenv("GEMINI_API_KEY")
    
    if not api_key:
        st.error("âš ï¸ Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        st.info("`.streamlit/secrets.toml` ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ì— `GEMINI_API_KEY`ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
        st.stop()

    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.markdown("## ğŸ“Š ë„êµ¬ ì •ë³´ (v2)")
        st.warning("**ë¹„ê³µì‹ ê°œì¸ í”„ë¡œì íŠ¸**")
        st.markdown("---")
        st.markdown("### â„¹ï¸ v2 ì£¼ìš” ê¸°ëŠ¥")
        st.info("""
        - **RAG (Retrieval-Augmented Generation)**:
          ë¬¸ì„œ ì „ì²´ë¥¼ ë²¡í„°í™”í•˜ì—¬ ì‹¬ì‚¬ í•­ëª©ê³¼
          ê´€ë ¨ëœ í•µì‹¬ ë‚´ìš©ë§Œ AIì— ì „ë‹¬
        - **JSON ëª¨ë“œ**: ì•ˆì •ì ì¸ ë¶„ì„ ê²°ê³¼
        - **ì„¸ë¶€ í•­ëª© ì±„ì **: ì •êµí•œ í”¼ë“œë°±
        - **ì˜¤ë¥˜ ë³µêµ¬**: RAG ì‹¤íŒ¨ ì‹œ ëŒ€ì²´ ë°©ì•ˆ ì œê³µ
        """)
        st.success("âœ… API ì—°ê²°ë¨")
    
    # ë©”ì¸ ì˜ì—­
    tab1, tab2, tab3 = st.tabs(["ğŸ“„ PDF ë¶„ì„ (ê¶Œì¥)", "ğŸ“ í…ìŠ¤íŠ¸ ë¶„ì„", "â„¹ï¸ ì‚¬ìš© ê°€ì´ë“œ"])
    
    try:
        auditor = KOICAAuditorStreamlit(api_key=api_key)
    except Exception as e:
        st.error(f"ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        st.stop()

    with tab1:
        st.markdown("### PDF ë³´ê³ ì„œ ì—…ë¡œë“œ")
        uploaded_file = st.file_uploader("KOICA ì˜ˆë¹„ì¡°ì‚¬ ë³´ê³ ì„œ (PDF)", type=['pdf'], key="pdf_uploader")
        
        if uploaded_file:
            st.success(f"âœ… íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ: {uploaded_file.name}")
            
            if st.button("ğŸš€ ë¶„ì„ ì‹œì‘ (RAG)", type="primary", key="analyze_pdf"):
                try:
                    # 1. í…ìŠ¤íŠ¸ ì¶”ì¶œ
                    full_text = auditor.extract_text_from_pdf(uploaded_file)
                    st.session_state['pdf_full_text'] = full_text
                    
                    if not full_text:
                        st.error("PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                    else:
                        # 2. ë¶„ì„ ìˆ˜í–‰
                        results = auditor.conduct_audit(full_text=full_text)
                        if results:
                            st.session_state['pdf_results'] = results
                    
                except Exception as e:
                    st.error(f"âŒ PDF ë¶„ì„ ì˜¤ë¥˜: {e}")
                    st.exception(e)
        
        # ê²°ê³¼ í‘œì‹œ
        if 'pdf_results' in st.session_state:
            results = st.session_state['pdf_results']
            display_results(results)
            
            report_text = generate_report_text(results)
            st.download_button(
                label="ğŸ“¥ ì‹¬ì‚¬ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ",
                data=report_text,
                file_name=f"KOICA_RAG_ì‹¬ì‚¬ê²°ê³¼_{datetime.now().strftime('%Y%m%d')}.txt",
                mime="text/plain",
                key="download_pdf"
            )
    
    with tab2:
        st.markdown("### í…ìŠ¤íŠ¸ ì§ì ‘ ì…ë ¥")
        text_input = st.text_area("ë³´ê³ ì„œ ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”", height=300, key="text_input")
        
        if st.button("ğŸš€ ë¶„ì„ ì‹œì‘ (RAG)", key="text_analyze", type="primary"):
            if text_input.strip():
                try:
                    results = auditor.conduct_audit(full_text=text_input)
                    if results:
                        st.session_state['text_results'] = results
                    
                except Exception as e:
                    st.error(f"âŒ í…ìŠ¤íŠ¸ ë¶„ì„ ì˜¤ë¥˜: {e}")
            else:
                st.warning("âš ï¸ ë¶„ì„í•  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
        
        if 'text_results' in st.session_state:
            results = st.session_state['text_results']
            display_results(results)
            
            report_text = generate_report_text(results)
            st.download_button(
                label="ğŸ“¥ ì‹¬ì‚¬ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ",
                data=report_text,
                file_name=f"KOICA_RAG_ì‹¬ì‚¬ê²°ê³¼_{datetime.now().strftime('%Y%m%d')}.txt",
                mime="text/plain",
                key="download_text"
            )
    
    with tab3:
        st.markdown("### ğŸ“– ì‚¬ìš© ê°€ì´ë“œ (v2 - RAG)")
        st.markdown("#### ğŸš€ RAG (Retrieval-Augmented Generation) ë€?")
        st.markdown("""
        ì´ì „ ë²„ì „(v1)ì€ ë³´ê³ ì„œì˜ **ì•ë¶€ë¶„ 4,000ì**ë§Œ ë¶„ì„í•˜ëŠ” í•œê³„ê°€ ìˆì—ˆìŠµë‹ˆë‹¤.
        
        **v2ì˜ RAG ë°©ì‹**ì€ ë‹¤ë¦…ë‹ˆë‹¤:
        1. **ë²¡í„°í™”:** PDF ë¬¸ì„œ ì „ì²´ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•œ ë’¤, ì˜ë¯¸ ë‹¨ìœ„(ì²­í¬)ë¡œ ì˜ë¼ 'ë²¡í„°'ë¡œ ë³€í™˜í•˜ì—¬ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤.
        2. **ê²€ìƒ‰:** 'ì •ì±… ë¶€í•©ì„±'ì„ ë¶„ì„í•  ë•, PDF ì „ì²´ì—ì„œ "SDGs", "CPS" ë“± ê´€ë ¨ ë‚´ìš©ë§Œ **ê²€ìƒ‰(Retrieval)**í•©ë‹ˆë‹¤.
        3. **ë¶„ì„:** AIëŠ” ê²€ìƒ‰ëœ **í•µì‹¬ ë‚´ìš©ë“¤ë§Œ**ì„ ë°”íƒ•ìœ¼ë¡œ ì‹¬ì‚¬ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.
        
        **ê²°ê³¼: 100í˜ì´ì§€ê°€ ë„˜ëŠ” ë¬¸ì„œë¼ë„ ì „ì²´ ë‚´ìš©ì„ ë¹ ì§ì—†ì´ ê²€í† í•˜ì—¬ í›¨ì”¬ ì •í™•í•œ ì‹¬ì‚¬ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤.**
        """)
        
        st.markdown("#### ğŸ”§ ì˜¤ë¥˜ ë°œìƒ ì‹œ ëŒ€ì²˜ ë°©ë²•")
        st.markdown("""
        **"Illegal metadata" ë˜ëŠ” "503" ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´:**
        - ì´ëŠ” Google APIì˜ ì¼ì‹œì  ë¬¸ì œì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤
        - ì‹œìŠ¤í…œì´ ìë™ìœ¼ë¡œ ëŒ€ì²´ ë°©ì•ˆ(ì „ì²´ í…ìŠ¤íŠ¸ ì•ë¶€ë¶„ ë¶„ì„)ì„ ì œê³µí•©ë‹ˆë‹¤
        - ëª‡ ë¶„ í›„ ë‹¤ì‹œ ì‹œë„í•˜ê±°ë‚˜, ë¬¸ì„œë¥¼ ë” ì‘ì€ ë¶€ë¶„ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ë¶„ì„í•˜ì„¸ìš”
        """)
        
        st.markdown("#### ğŸ“‹ KOICA ì‹¬ì‚¬ ê¸°ì¤€")
        st.markdown("""
        **1. êµ­ë‚´ì™¸ ì •ì±… ë¶€í•©ì„± (30ì )**
        - SDGsì™€ì˜ ì—°ê´€ì„± (10ì )
        - ìˆ˜ì›êµ­ ì •ì±… ë¶€í•©ì„± (5ì )
        - í•œêµ­ ì •ë¶€ CPS ë° êµ­ì •ê³¼ì œ ì—°ê³„ (5ì )
        - ì½”ì´ì¹´ ì¤‘ê¸°ì „ëµ ë¶€í•©ì„± (5ì )
        - íƒ€ ê³µì—¬ê¸°ê´€ ì¤‘ë³µ ë¶„ì„ (5ì )
        
        **2. ì‚¬ì—… ì¶”ì§„ ì—¬ê±´ (70ì )**
        - ìˆ˜ì›êµ­ ì¶”ì§„ì²´ê³„ (20ì )
        - êµ­ë‚´ ì¶”ì§„ì²´ê³„ (15ì )
        - ì‚¬ì—… ì¶”ì§„ì „ëµ (15ì )
        - ë¦¬ìŠ¤í¬ ê´€ë¦¬ (10ì )
        - ì„±ê³¼ê´€ë¦¬ (10ì )
        """)

    # í‘¸í„°
    st.markdown("---")
    st.markdown("<div style='text-align: center; color: #666;'>KOICA ì‚¬ì—… ì‹¬ì‚¬ ë¶„ì„ ë„êµ¬ v2 (RAG) | ë¹„ê³µì‹ ê°œì¸ í”„ë¡œì íŠ¸</div>", unsafe_allow_html=True)


if __name__ == "__main__":
    main()
