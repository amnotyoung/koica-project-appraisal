#!/usr/bin/env python3
"""
KOICA ì‚¬ì—… ì˜ˆë¹„ì¡°ì‚¬ ì‹¬ì‚¬ ì‹œìŠ¤í…œ - Streamlit Web App
(RAG v3 - ì„ë² ë”© ë°©ì‹ ê°œì„  ë²„ì „ - ìˆ˜ì •ë¨)
"""

import streamlit as st
import os
import json
import traceback
import time
from datetime import datetime
from typing import Dict, List, Any, Optional
from dataclasses import dataclass

# --- í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„í¬íŠ¸ ---
import PyPDF2
import google.generativeai as genai
from google.generativeai.types import GenerationConfig
import numpy as np

# --- í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(
    page_title="KOICA ì‹¬ì‚¬ ë¶„ì„ ë„êµ¬ v3 (RAG)",
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- CSS ìŠ¤íƒ€ì¼ ---
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        text-align: center;
        color: #666;
        margin-bottom: 2rem;
    }
    .score-box {
        padding: 20px;
        border-radius: 10px;
        margin: 20px 0;
        text-align: center;
    }
    .good-score { background-color: #d4edda; border: 2px solid #28a745; }
    .average-score { background-color: #fff3cd; border: 2px solid #ffc107; }
    .poor-score { background-color: #f8d7da; border: 2px solid #dc3545; }
    .disclaimer {
        background-color: #fff3cd;
        border-left: 5px solid #ffc107;
        padding: 15px;
        margin: 20px 0;
        border-radius: 5px;
    }
</style>
""", unsafe_allow_html=True)


# --- ë°ì´í„° í´ë˜ìŠ¤ ---
@dataclass
class AuditEvidence:
    """ì‹¬ì‚¬ ê·¼ê±° ë°ì´í„° í´ë˜ìŠ¤"""
    score: int
    max_score: int
    percentage: float
    detailed_scores: List[Dict[str, Any]]
    reasoning: str
    strengths: List[str]
    weaknesses: List[str]
    recommendations: List[str]


class SimpleVectorStore:
    """ê°„ë‹¨í•œ ë²¡í„° ìŠ¤í† ì–´ (Gemini API ì§ì ‘ ì‚¬ìš©)"""
    
    def __init__(self, api_key: str):
        self.api_key = api_key
        genai.configure(api_key=api_key)
        self.chunks = []
        self.embeddings = []
    
    def add_texts(self, texts: List[str], batch_size: int = 1):
        """í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©í•˜ì—¬ ì €ì¥ - ë‹¨ì¼ í…ìŠ¤íŠ¸ì”© ì²˜ë¦¬ë¡œ ë³€ê²½"""
        self.chunks = texts
        total = len(texts)
        
        progress_bar = st.progress(0)
        
        for i, text in enumerate(texts, 1):
            try:
                # ë‹¨ì¼ í…ìŠ¤íŠ¸ì”© ì„ë² ë”© ìƒì„± (ë°°ì¹˜ ë¬¸ì œ íšŒí”¼)
                result = genai.embed_content(
                    model="models/text-embedding-004",
                    content=text,
                    task_type="retrieval_document"
                )
                
                # ë‹¨ì¼ í…ìŠ¤íŠ¸ ì‘ë‹µ ì²˜ë¦¬
                if isinstance(result, dict) and 'embedding' in result:
                    self.embeddings.append(result['embedding'])
                elif isinstance(result, list):
                    self.embeddings.append(result)
                else:
                    st.warning(f"ì²­í¬ {i}: ì˜ˆìƒì¹˜ ëª»í•œ ì‘ë‹µ êµ¬ì¡°")
                    self.embeddings.append([0.0] * 768)
                
                progress = i / total
                progress_bar.progress(progress, text=f"ì„ë² ë”© ìƒì„± ì¤‘: {i}/{total}")
                
                # API Rate Limit ë°©ì§€
                if i % 10 == 0:
                    time.sleep(1)
                else:
                    time.sleep(0.3)
                
            except Exception as e:
                st.error(f"ì²­í¬ {i} ì„ë² ë”© ì‹¤íŒ¨: {e}")
                # ì‹¤íŒ¨í•œ ì²­í¬ëŠ” ë¹ˆ ì„ë² ë”©ìœ¼ë¡œ ì±„ì›€
                self.embeddings.append([0.0] * 768)
        
        progress_bar.empty()
        st.success(f"âœ… {len(self.embeddings)}ê°œ ì²­í¬ ì„ë² ë”© ì™„ë£Œ!")
    
    def similarity_search(self, query: str, k: int = 10) -> List[str]:
        """ì¿¼ë¦¬ì™€ ìœ ì‚¬í•œ ì²­í¬ ê²€ìƒ‰"""
        if not self.embeddings:
            return []
        
        try:
            # ì¿¼ë¦¬ ì„ë² ë”©
            result = genai.embed_content(
                model="models/text-embedding-004",
                content=query,
                task_type="retrieval_query"
            )
            
            # ì¿¼ë¦¬ ì„ë² ë”© ì‘ë‹µ ì²˜ë¦¬
            if isinstance(result, dict) and 'embedding' in result:
                query_embedding = result['embedding']
            elif isinstance(result, list):
                query_embedding = result
            else:
                st.warning(f"ì˜ˆìƒì¹˜ ëª»í•œ ì¿¼ë¦¬ ì‘ë‹µ êµ¬ì¡°: {type(result)}")
                return self.chunks[:k]
            
            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
            similarities = []
            for idx, doc_embedding in enumerate(self.embeddings):
                similarity = self._cosine_similarity(query_embedding, doc_embedding)
                similarities.append((idx, similarity))
            
            # ìƒìœ„ kê°œ ì„ íƒ
            similarities.sort(key=lambda x: x[1], reverse=True)
            top_k = similarities[:k]
            
            return [self.chunks[idx] for idx, _ in top_k]
            
        except Exception as e:
            st.warning(f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return self.chunks[:k]  # ì‹¤íŒ¨ ì‹œ ì•ë¶€ë¶„ ë°˜í™˜
    
    def _cosine_similarity(self, vec1: List[float], vec2: List[float]) -> float:
        """ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°"""
        try:
            vec1 = np.array(vec1)
            vec2 = np.array(vec2)
            
            # Zero division ë°©ì§€
            norm1 = np.linalg.norm(vec1)
            norm2 = np.linalg.norm(vec2)
            
            if norm1 == 0 or norm2 == 0:
                return 0.0
            
            return np.dot(vec1, vec2) / (norm1 * norm2)
        except Exception:
            return 0.0


class KOICAAuditorStreamlit:
    """KOICA ì‹¬ì‚¬ ì‹œìŠ¤í…œ - RAG v3"""
    
    def __init__(self, api_key: Optional[str] = None):
        """ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        self.audit_criteria = {
            "ì •ì±…ë¶€í•©ì„±": {
                "ë§Œì ": 30,
                "í•­ëª©": ["SDGs ì—°ê´€ì„±", "ìˆ˜ì›êµ­ ì •ì±…", "CPS/êµ­ì •ê³¼ì œ", "ì½”ì´ì¹´ ì „ëµ", "íƒ€ ê³µì—¬ê¸°ê´€"]
            },
            "ì¶”ì§„ì—¬ê±´": {
                "ë§Œì ": 70,
                "í•­ëª©": ["ìˆ˜ì›êµ­ ì¶”ì§„ì²´ê³„", "êµ­ë‚´ ì¶”ì§„ì²´ê³„", "ì‚¬ì—… ì¶”ì§„ì „ëµ", "ë¦¬ìŠ¤í¬ ê´€ë¦¬", "ì„±ê³¼ê´€ë¦¬"]
            }
        }
        
        if not api_key:
            raise ValueError("Gemini API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤")
        
        try:
            genai.configure(api_key=api_key)
            
            # JSON ëª¨ë“œ ì„¤ì •
            self.json_config = GenerationConfig(response_mime_type="application/json")
            
            # Gemini ëª¨ë¸ ì´ˆê¸°í™”
            self.model = genai.GenerativeModel(
                'gemini-2.5-pro',
                generation_config=self.json_config
            )
            
            self.api_key = api_key
            
        except Exception as e:
            raise Exception(f"Gemini API ì—°ê²° ì‹¤íŒ¨: {e}")
    
    def extract_text_from_pdf(self, pdf_file) -> str:
        """PDFì—ì„œ ì „ì²´ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        try:
            pdf_reader = PyPDF2.PdfReader(pdf_file)
            full_text = ""
            total_pages = len(pdf_reader.pages)
            
            progress_bar = st.progress(0, text="ğŸ“„ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘...")
            
            for page_num, page in enumerate(pdf_reader.pages, 1):
                try:
                    full_text += page.extract_text() + "\n"
                    progress = page_num / total_pages
                    progress_bar.progress(progress, text=f"í˜ì´ì§€ ì¶”ì¶œ ì¤‘: {page_num}/{total_pages}")
                except Exception:
                    st.warning(f"í˜ì´ì§€ {page_num} ì²˜ë¦¬ ì˜¤ë¥˜ (ê±´ë„ˆëœ€)")
            
            progress_bar.empty()
            return full_text
            
        except Exception as e:
            raise Exception(f"PDF ì²˜ë¦¬ ì˜¤ë¥˜: {e}")

    def create_vector_store(self, full_text: str) -> Optional[SimpleVectorStore]:
        """í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë‚˜ëˆ„ê³  ë²¡í„° ìŠ¤í† ì–´ ìƒì„±"""
        if not full_text:
            st.error("ì¶”ì¶œëœ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• 
        chunks = self._split_text(full_text, chunk_size=1500, overlap=200)
        
        if not chunks:
            st.error("í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë‚˜ëˆŒ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        st.info(f"ğŸ“¦ ì´ {len(chunks)}ê°œ ì²­í¬ ìƒì„±ë¨")
        
        try:
            vector_store = SimpleVectorStore(self.api_key)
            vector_store.add_texts(chunks)
            return vector_store
            
        except Exception as e:
            st.error(f"ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì‹¤íŒ¨: {e}")
            st.code(traceback.format_exc())
            return None
    
    def _split_text(self, text: str, chunk_size: int = 1500, overlap: int = 200) -> List[str]:
        """í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• """
        chunks = []
        start = 0
        text_length = len(text)
        
        while start < text_length:
            end = start + chunk_size
            chunk = text[start:end]
            chunks.append(chunk)
            start = end - overlap
        
        return chunks

    def get_relevant_context(self, vector_store: SimpleVectorStore, query: str, k: int = 10) -> str:
        """ë²¡í„° ìŠ¤í† ì–´ì—ì„œ ì¿¼ë¦¬ì™€ ê´€ë ¨ëœ Kê°œì˜ ì²­í¬ ê²€ìƒ‰"""
        if vector_store is None:
            return ""
        try:
            docs = vector_store.similarity_search(query, k=k)
            context = "\n---\n".join(docs)
            return context
        except Exception as e:
            st.warning(f"ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return ""

    def analyze_policy_alignment(self, vector_store: SimpleVectorStore = None, full_text: str = "") -> AuditEvidence:
        """[RAG ì ìš©] êµ­ë‚´ì™¸ ì •ì±… ë¶€í•©ì„± AI ë¶„ì„"""
        
        # RAG: ê´€ë ¨ì„± ë†’ì€ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰
        if vector_store:
            query = "êµ­ë‚´ì™¸ ì •ì±… ë¶€í•©ì„±, SDGs, ìˆ˜ì›êµ­ ê°œë°œ ì •ì±…, í•œêµ­ ì •ë¶€ CPS, ì½”ì´ì¹´ ì¤‘ê¸° ì „ëµ, íƒ€ ê³µì—¬ê¸°ê´€ ì§€ì› í˜„í™©, ODA"
            context = self.get_relevant_context(vector_store, query, k=15)
        else:
            context = full_text[:30000] if full_text else ""
        
        if not context:
            context = "ë³´ê³ ì„œì—ì„œ ê´€ë ¨ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        prompt = f"""ë‹¹ì‹ ì€ KOICA ì‚¬ì—… ì‹¬ì‚¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ë³´ê³ ì„œ ë°œì·Œ ë‚´ìš©ì„ 'êµ­ë‚´ì™¸ ì •ì±… ë¶€í•©ì„±' ê¸°ì¤€ìœ¼ë¡œ í‰ê°€í•˜ì„¸ìš”.

=== í‰ê°€ ê¸°ì¤€ (30ì  ë§Œì ) ===
1. SDGsì™€ì˜ ì—°ê´€ì„± (10ì )
2. ìˆ˜ì›êµ­ ì •ì±… ë¶€í•©ì„± (5ì )
3. í•œêµ­ ì •ë¶€ CPS ë° êµ­ì •ê³¼ì œ ì—°ê³„ (5ì )
4. ì½”ì´ì¹´ ì¤‘ê¸°ì „ëµ ë¶€í•©ì„± (5ì )
5. íƒ€ ê³µì—¬ê¸°ê´€ ì¤‘ë³µ ë¶„ì„ (5ì )

=== ë³´ê³ ì„œ ë°œì·Œ ë‚´ìš© ===
{context[:35000]}

=== ì¶œë ¥ í˜•ì‹ (JSON) ===
{{
  "total_score": 0-30 ì‚¬ì´ ì •ìˆ˜,
  "detailed_scores": [
    {{"item": "SDGs", "score": 0-10, "max_score": 10, "reason": "SDGs ì—°ê´€ì„±ì— ëŒ€í•œ í‰ê°€ ê·¼ê±°"}},
    {{"item": "ìˆ˜ì›êµ­ ì •ì±…", "score": 0-5, "max_score": 5, "reason": "ìˆ˜ì›êµ­ ì •ì±… ë¶€í•©ì„±ì— ëŒ€í•œ í‰ê°€ ê·¼ê±°"}},
    {{"item": "CPS/êµ­ì •ê³¼ì œ", "score": 0-5, "max_score": 5, "reason": "CPS/êµ­ì •ê³¼ì œ ì—°ê³„ì„±ì— ëŒ€í•œ í‰ê°€ ê·¼ê±°"}},
    {{"item": "ì½”ì´ì¹´ ì „ëµ", "score": 0-5, "max_score": 5, "reason": "ì½”ì´ì¹´ ì¤‘ê¸°ì „ëµ ë¶€í•©ì„±ì— ëŒ€í•œ í‰ê°€ ê·¼ê±°"}},
    {{"item": "íƒ€ ê³µì—¬ê¸°ê´€", "score": 0-5, "max_score": 5, "reason": "íƒ€ ê³µì—¬ê¸°ê´€ ì¤‘ë³µ ë¶„ì„ì— ëŒ€í•œ í‰ê°€ ê·¼ê±°"}}
  ],
  "reasoning": "ì ìˆ˜ ì‚°ì • ë…¼ë¦¬ ìƒì„¸ ì„¤ëª…",
  "strengths": ["ê°•ì 1", "ê°•ì 2"],
  "weaknesses": ["ì•½ì 1", "ì•½ì 2"],
  "recommendations": ["ê°œì„ ì•ˆ1", "ê°œì„ ì•ˆ2"]
}}

JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”."""

        try:
            response = self.model.generate_content(prompt)
            result = json.loads(response.text)
            
            return AuditEvidence(
                score=result['total_score'],
                max_score=30,
                percentage=round(result['total_score'] / 30 * 100, 1),
                detailed_scores=result.get('detailed_scores', []),
                reasoning=result.get('reasoning', ''),
                strengths=result.get('strengths', []),
                weaknesses=result.get('weaknesses', []),
                recommendations=result.get('recommendations', [])
            )
        except Exception as e:
            st.error(f"ì •ì±…ë¶€í•©ì„± ë¶„ì„ ì˜¤ë¥˜: {e}")
            return AuditEvidence(0, 30, 0.0, [], f"ë¶„ì„ ì‹¤íŒ¨: {e}", [], [], [])

    def analyze_implementation_readiness(self, vector_store: SimpleVectorStore = None, full_text: str = "") -> AuditEvidence:
        """[RAG ì ìš©] ì‚¬ì—… ì¶”ì§„ ì—¬ê±´ AI ë¶„ì„"""
        
        if vector_store:
            query = "ì‚¬ì—… ì¶”ì§„ ì—¬ê±´, ìˆ˜ì›êµ­ ì¶”ì§„ì²´ê³„, êµ­ë‚´ ì¶”ì§„ì²´ê³„, ì‚¬ì—… ì¶”ì§„ì „ëµ, ë¦¬ìŠ¤í¬ ê´€ë¦¬, ì„±ê³¼ê´€ë¦¬, ì˜ˆì‚°, ì¼ì •"
            context = self.get_relevant_context(vector_store, query, k=15)
        else:
            context = full_text[:30000] if full_text else ""
        
        if not context:
            context = "ë³´ê³ ì„œì—ì„œ ê´€ë ¨ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        prompt = f"""ë‹¹ì‹ ì€ KOICA ì‚¬ì—… ì‹¬ì‚¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ë³´ê³ ì„œ ë°œì·Œ ë‚´ìš©ì„ 'ì‚¬ì—… ì¶”ì§„ ì—¬ê±´' ê¸°ì¤€ìœ¼ë¡œ í‰ê°€í•˜ì„¸ìš”.

=== í‰ê°€ ê¸°ì¤€ (70ì  ë§Œì ) ===
1. ìˆ˜ì›êµ­ ì¶”ì§„ì²´ê³„ (20ì )
2. êµ­ë‚´ ì¶”ì§„ì²´ê³„ (15ì )
3. ì‚¬ì—… ì¶”ì§„ì „ëµ (15ì )
4. ë¦¬ìŠ¤í¬ ê´€ë¦¬ (10ì )
5. ì„±ê³¼ê´€ë¦¬ (10ì )

=== ë³´ê³ ì„œ ë°œì·Œ ë‚´ìš© ===
{context[:35000]}

=== ì¶œë ¥ í˜•ì‹ (JSON) ===
{{
  "total_score": 0-70 ì‚¬ì´ ì •ìˆ˜,
  "detailed_scores": [
    {{"item": "ìˆ˜ì›êµ­ ì¶”ì§„ì²´ê³„", "score": 0-20, "max_score": 20, "reason": "í‰ê°€ ê·¼ê±°"}},
    {{"item": "êµ­ë‚´ ì¶”ì§„ì²´ê³„", "score": 0-15, "max_score": 15, "reason": "í‰ê°€ ê·¼ê±°"}},
    {{"item": "ì‚¬ì—… ì¶”ì§„ì „ëµ", "score": 0-15, "max_score": 15, "reason": "í‰ê°€ ê·¼ê±°"}},
    {{"item": "ë¦¬ìŠ¤í¬ ê´€ë¦¬", "score": 0-10, "max_score": 10, "reason": "í‰ê°€ ê·¼ê±°"}},
    {{"item": "ì„±ê³¼ê´€ë¦¬", "score": 0-10, "max_score": 10, "reason": "í‰ê°€ ê·¼ê±°"}}
  ],
  "reasoning": "ì ìˆ˜ ì‚°ì • ë…¼ë¦¬ ìƒì„¸ ì„¤ëª…",
  "strengths": ["ê°•ì 1", "ê°•ì 2"],
  "weaknesses": ["ì•½ì 1", "ì•½ì 2"],
  "recommendations": ["ê°œì„ ì•ˆ1", "ê°œì„ ì•ˆ2"]
}}

JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”."""

        try:
            response = self.model.generate_content(prompt)
            result = json.loads(response.text)
            
            return AuditEvidence(
                score=result['total_score'],
                max_score=70,
                percentage=round(result['total_score'] / 70 * 100, 1),
                detailed_scores=result.get('detailed_scores', []),
                reasoning=result.get('reasoning', ''),
                strengths=result.get('strengths', []),
                weaknesses=result.get('weaknesses', []),
                recommendations=result.get('recommendations', [])
            )
        except Exception as e:
            st.error(f"ì¶”ì§„ì—¬ê±´ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return AuditEvidence(0, 70, 0.0, [], f"ë¶„ì„ ì‹¤íŒ¨: {e}", [], [], [])

    def conduct_audit(self, full_text: str) -> Optional[Dict[str, Any]]:
        """ì „ì²´ ì‹¬ì‚¬ ìˆ˜í–‰ (RAG ê¸°ë°˜)"""
        start_time = datetime.now()
        
        try:
            # 1. ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì‹œë„
            vector_store = self.create_vector_store(full_text)
            
            if not vector_store:
                st.warning("âš ï¸ RAG ëª¨ë“œ ì‹¤íŒ¨. ì „ì²´ í…ìŠ¤íŠ¸ ì•ë¶€ë¶„ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.")
            
            # 2. ì •ì±… ë¶€í•©ì„± ë¶„ì„
            with st.spinner("ğŸŒ ì •ì±… ë¶€í•©ì„± ë¶„ì„ ì¤‘..."):
                policy_result = self.analyze_policy_alignment(vector_store, full_text)
            
            # 3. ì¶”ì§„ ì—¬ê±´ ë¶„ì„
            with st.spinner("ğŸ—ï¸ ì‚¬ì—… ì¶”ì§„ ì—¬ê±´ ë¶„ì„ ì¤‘..."):
                impl_result = self.analyze_implementation_readiness(vector_store, full_text)
            
            # 4. ê²°ê³¼ ì¢…í•©
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()
            
            results = {
                "ì´ì ": policy_result.score + impl_result.score,
                "ì •ì±…ë¶€í•©ì„±": {
                    "ì ìˆ˜": policy_result.score,
                    "ë§Œì ": policy_result.max_score,
                    "ë°±ë¶„ìœ¨": policy_result.percentage,
                    "ì„¸ë¶€ì ìˆ˜": policy_result.detailed_scores,
                    "ê°•ì ": policy_result.strengths,
                    "ì•½ì ": policy_result.weaknesses,
                    "ì œì•ˆ": policy_result.recommendations
                },
                "ì¶”ì§„ì—¬ê±´": {
                    "ì ìˆ˜": impl_result.score,
                    "ë§Œì ": impl_result.max_score,
                    "ë°±ë¶„ìœ¨": impl_result.percentage,
                    "ì„¸ë¶€ì ìˆ˜": impl_result.detailed_scores,
                    "ê°•ì ": impl_result.strengths,
                    "ì•½ì ": impl_result.weaknesses,
                    "ì œì•ˆ": impl_result.recommendations
                },
                "ë¶„ì„ì‹œê°„": f"{duration:.1f}ì´ˆ",
                "RAG_ì‚¬ìš©": vector_store is not None
            }
            
            return results
            
        except Exception as e:
            st.error(f"âŒ ì‹¬ì‚¬ ìˆ˜í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
            st.code(traceback.format_exc())
            return None


def display_results(results: Dict[str, Any]):
    """ë¶„ì„ ê²°ê³¼ í‘œì‹œ"""
    # RAG ì‚¬ìš© ì—¬ë¶€ í‘œì‹œ
    if not results.get('RAG_ì‚¬ìš©', False):
        st.warning("âš ï¸ ì´ ë¶„ì„ì€ RAG ì—†ì´ ìˆ˜í–‰ë˜ì—ˆìŠµë‹ˆë‹¤. ì „ì²´ ë¬¸ì„œê°€ ì•„ë‹Œ ì•ë¶€ë¶„ë§Œ ë¶„ì„ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    else:
        st.success("âœ… RAG ê¸°ë°˜ ì „ì²´ ë¬¸ì„œ ë¶„ì„ ì™„ë£Œ")
    
    # ì´ì  í‘œì‹œ
    total_score = results['ì´ì ']
    score_class = "good-score" if total_score >= 80 else "average-score" if total_score >= 60 else "poor-score"
    st.markdown(f"""
    <div class="score-box {score_class}">
        <h2>ì´ì : {total_score} / 100</h2>
        <p>ë¶„ì„ ì‹œê°„: {results['ë¶„ì„ì‹œê°„']}</p>
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown("### ğŸ“‹ í•­ëª©ë³„ í‰ê°€")
    col1, col2 = st.columns(2)
    
    with col1:
        policy = results['ì •ì±…ë¶€í•©ì„±']
        st.markdown("#### ğŸŒ êµ­ë‚´ì™¸ ì •ì±… ë¶€í•©ì„±")
        st.metric("ì ìˆ˜", f"{policy['ì ìˆ˜']}/{policy['ë§Œì ']}", f"{policy['ë°±ë¶„ìœ¨']:.1f}%")
        
        with st.expander("ìƒì„¸ ë¶„ì„ ë³´ê¸°"):
            st.markdown("**ğŸ“Œ ì„¸ë¶€ í•­ëª© í‰ê°€**")
            for item in policy['ì„¸ë¶€ì ìˆ˜']:
                st.markdown(f"**{item['item']} ({item['score']}/{item['max_score']})**")
                st.caption(f"_{item['reason']}_")
            
            st.markdown("---")
            st.markdown("**âœ… ê°•ì **")
            for s in policy['ê°•ì ']:
                st.markdown(f"- {s}")
            st.markdown("**âš ï¸ ì•½ì **")
            for w in policy['ì•½ì ']:
                st.markdown(f"- {w}")
            st.markdown("**ğŸ’¡ ê°œì„  ì œì•ˆ**")
            for r in policy['ì œì•ˆ']:
                st.markdown(f"- {r}")
    
    with col2:
        impl = results['ì¶”ì§„ì—¬ê±´']
        st.markdown("#### ğŸ—ï¸ ì‚¬ì—… ì¶”ì§„ ì—¬ê±´")
        st.metric("ì ìˆ˜", f"{impl['ì ìˆ˜']}/{impl['ë§Œì ']}", f"{impl['ë°±ë¶„ìœ¨']:.1f}%")
        
        with st.expander("ìƒì„¸ ë¶„ì„ ë³´ê¸°"):
            st.markdown("**ğŸ“Œ ì„¸ë¶€ í•­ëª© í‰ê°€**")
            for item in impl['ì„¸ë¶€ì ìˆ˜']:
                st.markdown(f"**{item['item']} ({item['score']}/{item['max_score']})**")
                st.caption(f"_{item['reason']}_")

            st.markdown("---")
            st.markdown("**âœ… ê°•ì **")
            for s in impl['ê°•ì ']:
                st.markdown(f"- {s}")
            st.markdown("**âš ï¸ ì•½ì **")
            for w in impl['ì•½ì ']:
                st.markdown(f"- {w}")
            st.markdown("**ğŸ’¡ ê°œì„  ì œì•ˆ**")
            for r in impl['ì œì•ˆ']:
                st.markdown(f"- {r}")


def generate_report_text(results: Dict[str, Any]) -> str:
    """í…ìŠ¤íŠ¸ ë³´ê³ ì„œ ìƒì„±"""
    lines = []
    lines.append("=" * 80)
    lines.append("KOICA ì‚¬ì—… ì‹¬ì‚¬ ë¶„ì„ ê²°ê³¼ (AI-RAG v3)")
    lines.append("=" * 80)
    lines.append(f"ë¶„ì„ ì¼ì‹œ: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M:%S')}")
    lines.append(f"ë¶„ì„ ì‹œê°„: {results['ë¶„ì„ì‹œê°„']}")
    lines.append(f"RAG ì‚¬ìš©: {'ì˜ˆ' if results.get('RAG_ì‚¬ìš©', False) else 'ì•„ë‹ˆì˜¤'}")
    lines.append(f"ì´ì : {results['ì´ì ']} / 100\n")
    
    # ì •ì±… ë¶€í•©ì„±
    policy = results['ì •ì±…ë¶€í•©ì„±']
    lines.append(f"\n[1] êµ­ë‚´ì™¸ ì •ì±… ë¶€í•©ì„± ({policy['ì ìˆ˜']}/{policy['ë§Œì ']})")
    lines.append("-" * 80)
    lines.append("\nì„¸ë¶€ í‰ê°€:")
    for item in policy['ì„¸ë¶€ì ìˆ˜']:
        lines.append(f"  â€¢ {item['item']} ({item['score']}/{item['max_score']})")
        lines.append(f"    â”” ê·¼ê±°: {item['reason']}")
    lines.append("\nê°•ì :")
    for s in policy['ê°•ì ']:
        lines.append(f"  âœ“ {s}")
    lines.append("\nì•½ì :")
    for w in policy['ì•½ì ']:
        lines.append(f"  âœ— {w}")
    lines.append("\nê°œì„  ì œì•ˆ:")
    for r in policy['ì œì•ˆ']:
        lines.append(f"  â†’ {r}")
    
    # ì¶”ì§„ ì—¬ê±´
    impl = results['ì¶”ì§„ì—¬ê±´']
    lines.append(f"\n\n[2] ì‚¬ì—… ì¶”ì§„ ì—¬ê±´ ({impl['ì ìˆ˜']}/{impl['ë§Œì ']})")
    lines.append("-" * 80)
    lines.append("\nì„¸ë¶€ í‰ê°€:")
    for item in impl['ì„¸ë¶€ì ìˆ˜']:
        lines.append(f"  â€¢ {item['item']} ({item['score']}/{item['max_score']})")
        lines.append(f"    â”” ê·¼ê±°: {item['reason']}")
    lines.append("\nê°•ì :")
    for s in impl['ê°•ì ']:
        lines.append(f"  âœ“ {s}")
    lines.append("\nì•½ì :")
    for w in impl['ì•½ì ']:
        lines.append(f"  âœ— {w}")
    lines.append("\nê°œì„  ì œì•ˆ:")
    for r in impl['ì œì•ˆ']:
        lines.append(f"  â†’ {r}")
    
    lines.append("\n\n" + "=" * 80)
    lines.append("ë©´ì±… ì¡°í•­")
    lines.append("=" * 80)
    lines.append("ë³¸ ë¶„ì„ ê²°ê³¼ëŠ” AI ê¸°ë°˜ ì°¸ê³ ìš©ì´ë©°, KOICA ê³µì‹ ì‹¬ì‚¬ ê²°ê³¼ê°€ ì•„ë‹™ë‹ˆë‹¤.")
    lines.append("ì‹¤ì œ ì‹¬ì‚¬ëŠ” ì „ë¬¸ê°€ì˜ ì¢…í•©ì  íŒë‹¨ìœ¼ë¡œ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤.")
    
    return "\n".join(lines)


# ========== ë©”ì¸ ì•± ==========

def main():
    st.markdown('<h1 class="main-header">ğŸš€ KOICA ì‚¬ì—… ì‹¬ì‚¬ ë¶„ì„ ë„êµ¬ (RAG v3)</h1>', unsafe_allow_html=True)
    st.markdown('<p class="sub-header">ê°œì„ ëœ RAG Â· ë¹„ê³µì‹ ê°œì¸ í”„ë¡œì íŠ¸</p>', unsafe_allow_html=True)
    
    # Disclaimer
    st.markdown("""
    <div class="disclaimer">
        <strong>âš ï¸ ì£¼ì˜ì‚¬í•­</strong><br>
        ë³¸ ë„êµ¬ëŠ” <strong>KOICA ê³µì‹ ì„œë¹„ìŠ¤ê°€ ì•„ë‹™ë‹ˆë‹¤</strong>. ê°œì¸ì´ KOICA ì‹¬ì‚¬ ê¸°ì¤€ì„ ì°¸ê³ í•˜ì—¬ ë…ìì ìœ¼ë¡œ ê°œë°œí•œ ë¶„ì„ ë„êµ¬ì…ë‹ˆë‹¤. ë¶„ì„ ê²°ê³¼ëŠ” ì°¸ê³ ìš©ì´ë©°, ê³µì‹ì ì¸ ì‹¬ì‚¬ ê²°ê³¼ì™€ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    </div>
    """, unsafe_allow_html=True)
    
    # API í‚¤ ë¡œë“œ
    api_key = None
    try:
        api_key = st.secrets["GEMINI_API_KEY"]
    except:
        api_key = os.getenv("GEMINI_API_KEY")
    
    if not api_key:
        st.error("âš ï¸ Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        st.info("`.streamlit/secrets.toml` ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ì— `GEMINI_API_KEY`ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
        st.stop()

    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.markdown("## ğŸ“Š ë„êµ¬ ì •ë³´ (v3 - ìˆ˜ì •ë¨)")
        st.warning("**ë¹„ê³µì‹ ê°œì¸ í”„ë¡œì íŠ¸**")
        st.markdown("---")
        st.markdown("### â„¹ï¸ v3 ê°œì„  ì‚¬í•­")
        st.info("""
        - âœ… **ì„ë² ë”© API ë‹¨ì¼ ì²˜ë¦¬ë¡œ ë³€ê²½**
        - **ì•ˆì •ì ì¸ ì„ë² ë”©**: Gemini API ì§ì ‘ ì‚¬ìš©
        - **ë°°ì¹˜ ë¬¸ì œ í•´ê²°**: ë‹¨ì¼ í…ìŠ¤íŠ¸ì”© ì²˜ë¦¬
        - **ì˜¤ë¥˜ ë³µêµ¬**: ì‹¤íŒ¨ ì‹œ ìë™ ëŒ€ì²´
        - **ì§„í–‰ ìƒí™© í‘œì‹œ**: ì‹¤ì‹œê°„ í”„ë¡œê·¸ë ˆìŠ¤ë°”
        """)
        st.success("âœ… API ì—°ê²°ë¨")
    
    # ë©”ì¸ ì˜ì—­
    tab1, tab2, tab3 = st.tabs(["ğŸ“„ PDF ë¶„ì„ (ê¶Œì¥)", "ğŸ“ í…ìŠ¤íŠ¸ ë¶„ì„", "â„¹ï¸ ì‚¬ìš© ê°€ì´ë“œ"])
    
    try:
        auditor = KOICAAuditorStreamlit(api_key=api_key)
    except Exception as e:
        st.error(f"ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        st.stop()

    with tab1:
        st.markdown("### PDF ë³´ê³ ì„œ ì—…ë¡œë“œ")
        uploaded_file = st.file_uploader("KOICA ì˜ˆë¹„ì¡°ì‚¬ ë³´ê³ ì„œ (PDF)", type=['pdf'], key="pdf_uploader")
        
        if uploaded_file:
            st.success(f"âœ… íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ: {uploaded_file.name}")
            
            if st.button("ğŸš€ ë¶„ì„ ì‹œì‘ (RAG v3)", type="primary", key="analyze_pdf"):
                try:
                    # 1. í…ìŠ¤íŠ¸ ì¶”ì¶œ
                    full_text = auditor.extract_text_from_pdf(uploaded_file)
                    st.session_state['pdf_full_text'] = full_text
                    
                    if not full_text:
                        st.error("PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                    else:
                        # 2. ë¶„ì„ ìˆ˜í–‰
                        results = auditor.conduct_audit(full_text=full_text)
                        if results:
                            st.session_state['pdf_results'] = results
                    
                except Exception as e:
                    st.error(f"âŒ PDF ë¶„ì„ ì˜¤ë¥˜: {e}")
                    st.exception(e)
        
        # ê²°ê³¼ í‘œì‹œ
        if 'pdf_results' in st.session_state:
            results = st.session_state['pdf_results']
            display_results(results)
            
            report_text = generate_report_text(results)
            st.download_button(
                label="ğŸ“¥ ì‹¬ì‚¬ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ",
                data=report_text,
                file_name=f"KOICA_RAG_ì‹¬ì‚¬ê²°ê³¼_{datetime.now().strftime('%Y%m%d')}.txt",
                mime="text/plain",
                key="download_pdf"
            )
    
    with tab2:
        st.markdown("### í…ìŠ¤íŠ¸ ì§ì ‘ ì…ë ¥")
        text_input = st.text_area("ë³´ê³ ì„œ ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”", height=300, key="text_input")
        
        if st.button("ğŸš€ ë¶„ì„ ì‹œì‘ (RAG v3)", key="text_analyze", type="primary"):
            if text_input.strip():
                try:
                    results = auditor.conduct_audit(full_text=text_input)
                    if results:
                        st.session_state['text_results'] = results
                    
                except Exception as e:
                    st.error(f"âŒ í…ìŠ¤íŠ¸ ë¶„ì„ ì˜¤ë¥˜: {e}")
            else:
                st.warning("âš ï¸ ë¶„ì„í•  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
        
        if 'text_results' in st.session_state:
            results = st.session_state['text_results']
            display_results(results)
            
            report_text = generate_report_text(results)
            st.download_button(
                label="ğŸ“¥ ì‹¬ì‚¬ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ",
                data=report_text,
                file_name=f"KOICA_RAG_ì‹¬ì‚¬ê²°ê³¼_{datetime.now().strftime('%Y%m%d')}.txt",
                mime="text/plain",
                key="download_text"
            )
    
    with tab3:
        st.markdown("### ğŸ“– ì‚¬ìš© ê°€ì´ë“œ (v3 - ê°œì„ ëœ RAG)")
        st.markdown("#### ğŸ”§ v3ì˜ ì£¼ìš” ê°œì„ ì‚¬í•­")
        st.markdown("""
        **ë¬¸ì œ í•´ê²°:**
        - âœ… **ì„ë² ë”© ë°°ì¹˜ ì²˜ë¦¬ ë¬¸ì œ í•´ê²° (ë‹¨ì¼ ì²˜ë¦¬ë¡œ ë³€ê²½)**
        - v2ì—ì„œ ë°œìƒí–ˆë˜ "Illegal metadata" ì˜¤ë¥˜ í•´ê²°
        - Langchain ì˜ì¡´ì„± ì œê±°, Gemini API ì§ì ‘ ì‚¬ìš©
        - ë” ì•ˆì •ì ì´ê³  ë¹ ë¥¸ ì„ë² ë”© ì²˜ë¦¬
        
        **ì„±ëŠ¥ í–¥ìƒ:**
        - ë‹¨ì¼ í…ìŠ¤íŠ¸ì”© ì²˜ë¦¬ë¡œ ì•ˆì •ì„± í™•ë³´
        - ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™© í‘œì‹œ
        - ì˜¤ë¥˜ ë°œìƒ ì‹œ ìë™ ë³µêµ¬
        - í–¥ìƒëœ ì˜¤ë¥˜ ì²˜ë¦¬ ë° ë””ë²„ê¹… ë©”ì‹œì§€
        """)
        
        st.markdown("#### ğŸš€ RAG ì‘ë™ ë°©ì‹")
        st.markdown("""
        1. **ë¬¸ì„œ ë¶„í• **: ì „ì²´ PDFë¥¼ 1,500ì ë‹¨ìœ„ ì²­í¬ë¡œ ë¶„í• 
        2. **ë²¡í„°í™”**: ê° ì²­í¬ë¥¼ 768ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜ (ë‹¨ì¼ í…ìŠ¤íŠ¸ì”© ì²˜ë¦¬)
        3. **ê²€ìƒ‰**: ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ìƒìœ„ 15ê°œ ì²­í¬ ê²€ìƒ‰
        4. **ë¶„ì„**: ê²€ìƒ‰ëœ í•µì‹¬ ë‚´ìš©ë§Œìœ¼ë¡œ AI ë¶„ì„ ìˆ˜í–‰
        """)
        
        st.markdown("#### ğŸ“‹ KOICA ì‹¬ì‚¬ ê¸°ì¤€")
        st.markdown("""
        **1. êµ­ë‚´ì™¸ ì •ì±… ë¶€í•©ì„± (30ì )**
        - SDGsì™€ì˜ ì—°ê´€ì„± (10ì )
        - ìˆ˜ì›êµ­ ì •ì±… ë¶€í•©ì„± (5ì )
        - í•œêµ­ ì •ë¶€ CPS ë° êµ­ì •ê³¼ì œ ì—°ê³„ (5ì )
        - ì½”ì´ì¹´ ì¤‘ê¸°ì „ëµ ë¶€í•©ì„± (5ì )
        - íƒ€ ê³µì—¬ê¸°ê´€ ì¤‘ë³µ ë¶„ì„ (5ì )
        
        **2. ì‚¬ì—… ì¶”ì§„ ì—¬ê±´ (70ì )**
        - ìˆ˜ì›êµ­ ì¶”ì§„ì²´ê³„ (20ì )
        - êµ­ë‚´ ì¶”ì§„ì²´ê³„ (15ì )
        - ì‚¬ì—… ì¶”ì§„ì „ëµ (15ì )
        - ë¦¬ìŠ¤í¬ ê´€ë¦¬ (10ì )
        - ì„±ê³¼ê´€ë¦¬ (10ì )
        """)

    # í‘¸í„°
    st.markdown("---")
    st.markdown("<div style='text-align: center; color: #666;'>KOICA ì‚¬ì—… ì‹¬ì‚¬ ë¶„ì„ ë„êµ¬ v3 (ê°œì„ ëœ RAG) | ë¹„ê³µì‹ ê°œì¸ í”„ë¡œì íŠ¸</div>", unsafe_allow_html=True)


if __name__ == "__main__":
    main()
